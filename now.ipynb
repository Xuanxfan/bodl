{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bs_price(S,K,sigma,r,T, year_rate = 252, option_type = \"call\"):\n",
    "    '''\n",
    "    bs 期权定价 输出为期权价格\n",
    "    输入格式：\n",
    "    S:标的价格\n",
    "    K:行权价\n",
    "    sigma:波动率\n",
    "    r:无风险利率\n",
    "    T:年华剩余期限\n",
    "    year_rate:年化系数\n",
    "    '''\n",
    "\n",
    "    T = T/year_rate\n",
    "    d1 = (np.log(S/K) + (r + pow(sigma,2)/2)*T) / (sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma*np.sqrt(T)\n",
    "    if option_type == 'call':\n",
    "        # return S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)\n",
    "        return np.maximum(S - K, 0) if T==0 else S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)\n",
    "    else :\n",
    "        # return K*np.exp(-r*T)*norm.cdf(-d2) - S*norm.cdf(-d1)\n",
    "        return np.maximum(K-S,0) if T==0 else K*np.exp(-r*T)*norm.cdf(-1*d2) - S*norm.cdf(-1*d1)\n",
    "\n",
    "def bs_vega(S,K,sigma,r,T ,year_rate = 252):\n",
    "    '''\n",
    "    计算vega\n",
    "    '''\n",
    "    T = T/year_rate\n",
    "    d1 = (np.log(S/K) + (r + pow(sigma,2)/2)*T) / (sigma*np.sqrt(np.abs(T)) )\n",
    "    return S*norm.pdf(d1)*np.sqrt(np.abs(T))\n",
    "    # return S * np.sqrt(abs(T)) * np.exp(-pow(d1,2)/2) / np.sqrt(2*np.pi)\n",
    "\n",
    "def iv_bs_bisection(S, K, r, T, price, option_type, iv_uplimit = 0.985, iv_downlimit = 0.015, precision = 3, year_rate = 365, max_iterations = 400):\n",
    "    '''二分法求iv'''\n",
    "    left_iv, right_iv = iv_downlimit, iv_uplimit\n",
    "    # left_price = BS_price(S,K,left_iv, r, T,  year_rate = year_rate, option_type = option_type)\n",
    "    # right_price= BS_price(S,K,right_iv, r, T,  year_rate = year_rate, option_type = option_type)\n",
    "    mid_iv = (left_iv + right_iv)/2\n",
    "    mid_price = bs_price(S,K,mid_iv, r, T,  year_rate = year_rate, option_type = option_type)\n",
    "    # print(f\"first, the mid price is {mid_price}, the price is {price}\")\n",
    "    cnt = 0\n",
    "    while abs(price - mid_price) >= 0.1**precision and cnt < max_iterations:\n",
    "        if mid_price < price :\n",
    "            left_iv = mid_iv\n",
    "        else:\n",
    "            right_iv = mid_iv\n",
    "        mid_iv = (left_iv + right_iv)/2\n",
    "        # if mid_iv < iv_uplimit or mid_iv > iv_downlimit:\n",
    "        #     break\n",
    "        # print(f\"cnt = {cnt}, the left is{left_iv}, the right is{right_iv}, the mid is {mid_iv}\")\n",
    "        cnt += 1\n",
    "        mid_price = bs_price(S, K, mid_iv, r, T,  year_rate = year_rate, option_type = option_type)\n",
    "    return mid_iv\n",
    "\n",
    "def find_vol_newton( S, K, r, T, target_value, option_type, start_sigma = 0.5, precision = 3, year_rate = 252, max_iterations = 200):\n",
    "    '''迭代法求iv'''\n",
    "    sigma = start_sigma\n",
    "    for i in range(0, max_iterations):\n",
    "        bs_price_ = bs_price(S,K,sigma,r,T, year_rate = year_rate, option_type = option_type)\n",
    "        vega = bs_vega(S, K, T, r, sigma, year_rate = year_rate)*100\n",
    "        diff = target_value - bs_price_  # our root\n",
    "        if (abs(diff) < 0.1**precision):\n",
    "            return sigma\n",
    "        sigma = sigma + diff/(vega) # f(x) / f'(x)\n",
    "    return sigma # value wasn't found, return best guess so far\n",
    "\n",
    "def change(type_name):\n",
    "    if type_name == '认购':\n",
    "        return \"call\"\n",
    "    elif type_name == '认沽':\n",
    "        return \"put\"\n",
    "    else:\n",
    "        return \"wrong_type\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000001.csv\n",
      "10000002.csv\n",
      "10000003.csv\n",
      "10000004.csv\n",
      "10000005.csv\n",
      "10000006.csv\n",
      "10000007.csv\n",
      "10000008.csv\n",
      "10000009.csv\n",
      "10000010.csv\n",
      "10000011.csv\n",
      "10000012.csv\n",
      "10000013.csv\n",
      "10000014.csv\n",
      "10000015.csv\n",
      "10000016.csv\n",
      "10000017.csv\n",
      "10000018.csv\n",
      "10000019.csv\n",
      "10000020.csv\n",
      "10000021.csv\n",
      "10000022.csv\n",
      "10000023.csv\n",
      "10000024.csv\n",
      "10000025.csv\n",
      "10000026.csv\n",
      "10000027.csv\n",
      "10000028.csv\n",
      "10000029.csv\n",
      "10000030.csv\n",
      "10000031.csv\n",
      "10000032.csv\n",
      "10000033.csv\n",
      "10000034.csv\n",
      "10000035.csv\n",
      "10000036.csv\n",
      "10000037.csv\n",
      "10000038.csv\n",
      "10000039.csv\n",
      "10000040.csv\n",
      "10000041.csv\n",
      "10000042.csv\n",
      "10000043.csv\n",
      "10000044.csv\n",
      "10000045.csv\n",
      "10000046.csv\n",
      "10000047.csv\n",
      "10000048.csv\n",
      "10000049.csv\n",
      "10000050.csv\n",
      "10000051.csv\n",
      "10000052.csv\n",
      "10000053.csv\n",
      "10000054.csv\n",
      "10000055.csv\n",
      "10000056.csv\n",
      "10000057.csv\n",
      "10000058.csv\n",
      "10000059.csv\n",
      "10000060.csv\n",
      "10000061.csv\n",
      "10000062.csv\n",
      "10000063.csv\n",
      "10000064.csv\n",
      "10000065.csv\n",
      "10000066.csv\n",
      "10000067.csv\n",
      "10000068.csv\n",
      "10000069.csv\n",
      "10000070.csv\n",
      "10000071.csv\n",
      "10000072.csv\n",
      "10000073.csv\n",
      "10000074.csv\n",
      "10000075.csv\n",
      "10000076.csv\n",
      "10000077.csv\n",
      "10000078.csv\n",
      "10000079.csv\n",
      "10000080.csv\n",
      "10000081.csv\n",
      "10000082.csv\n",
      "10000083.csv\n",
      "10000084.csv\n",
      "10000085.csv\n",
      "10000086.csv\n",
      "10000087.csv\n",
      "10000088.csv\n",
      "10000089.csv\n",
      "10000090.csv\n",
      "10000091.csv\n",
      "10000092.csv\n",
      "10000093.csv\n",
      "10000094.csv\n",
      "10000095.csv\n",
      "10000096.csv\n",
      "10000097.csv\n",
      "10000098.csv\n",
      "10000099.csv\n",
      "10000100.csv\n",
      "10000101.csv\n",
      "10000102.csv\n",
      "10000103.csv\n",
      "10000104.csv\n",
      "10000105.csv\n",
      "10000106.csv\n",
      "10000107.csv\n",
      "10000108.csv\n",
      "10000109.csv\n",
      "10000110.csv\n",
      "10000111.csv\n",
      "10000112.csv\n",
      "10000113.csv\n",
      "10000114.csv\n",
      "10000115.csv\n",
      "10000116.csv\n",
      "10000117.csv\n",
      "10000118.csv\n",
      "10000119.csv\n",
      "10000120.csv\n",
      "10000121.csv\n",
      "10000122.csv\n",
      "10000123.csv\n",
      "10000124.csv\n",
      "10000125.csv\n",
      "10000126.csv\n",
      "10000127.csv\n",
      "10000128.csv\n",
      "10000129.csv\n",
      "10000130.csv\n",
      "10000131.csv\n",
      "10000132.csv\n",
      "10000133.csv\n",
      "10000134.csv\n",
      "10000135.csv\n",
      "10000136.csv\n",
      "10000137.csv\n",
      "10000138.csv\n",
      "10000139.csv\n",
      "10000140.csv\n",
      "10000141.csv\n",
      "10000142.csv\n",
      "10000143.csv\n",
      "10000144.csv\n",
      "10000145.csv\n",
      "10000146.csv\n",
      "10000147.csv\n",
      "10000148.csv\n",
      "10000149.csv\n",
      "10000150.csv\n",
      "10000151.csv\n",
      "10000152.csv\n",
      "10000153.csv\n",
      "10000154.csv\n",
      "10000155.csv\n",
      "10000156.csv\n",
      "10000157.csv\n",
      "10000158.csv\n",
      "10000159.csv\n",
      "10000160.csv\n",
      "10000161.csv\n",
      "10000162.csv\n",
      "10000163.csv\n",
      "10000164.csv\n",
      "10000165.csv\n",
      "10000166.csv\n",
      "10000167.csv\n",
      "10000168.csv\n",
      "10000169.csv\n",
      "10000170.csv\n",
      "10000171.csv\n",
      "10000172.csv\n",
      "10000173.csv\n",
      "10000174.csv\n",
      "10000175.csv\n",
      "10000176.csv\n",
      "10000177.csv\n",
      "10000178.csv\n",
      "10000179.csv\n",
      "10000180.csv\n",
      "10000181.csv\n",
      "10000182.csv\n",
      "10000183.csv\n",
      "10000184.csv\n",
      "10000185.csv\n",
      "10000186.csv\n",
      "10000187.csv\n",
      "10000188.csv\n",
      "10000189.csv\n",
      "10000190.csv\n",
      "10000191.csv\n",
      "10000192.csv\n",
      "10000193.csv\n",
      "10000194.csv\n",
      "10000195.csv\n",
      "10000196.csv\n",
      "10000197.csv\n",
      "10000198.csv\n",
      "10000199.csv\n",
      "10000200.csv\n",
      "10000201.csv\n",
      "10000202.csv\n",
      "10000203.csv\n",
      "10000204.csv\n",
      "10000205.csv\n",
      "10000206.csv\n",
      "10000207.csv\n",
      "10000208.csv\n",
      "10000209.csv\n",
      "10000210.csv\n",
      "10000211.csv\n",
      "10000212.csv\n",
      "10000213.csv\n",
      "10000214.csv\n",
      "10000215.csv\n",
      "10000216.csv\n",
      "10000217.csv\n",
      "10000218.csv\n",
      "10000219.csv\n",
      "10000220.csv\n",
      "10000221.csv\n",
      "10000222.csv\n",
      "10000223.csv\n",
      "10000224.csv\n",
      "10000225.csv\n",
      "10000226.csv\n",
      "10000227.csv\n",
      "10000228.csv\n",
      "10000229.csv\n",
      "10000230.csv\n",
      "10000231.csv\n",
      "10000232.csv\n",
      "10000233.csv\n",
      "10000234.csv\n",
      "10000235.csv\n",
      "10000236.csv\n",
      "10000237.csv\n",
      "10000238.csv\n",
      "10000239.csv\n",
      "10000240.csv\n",
      "10000241.csv\n",
      "10000242.csv\n",
      "10000243.csv\n",
      "10000244.csv\n",
      "10000245.csv\n",
      "10000246.csv\n",
      "10000247.csv\n",
      "10000248.csv\n",
      "10000249.csv\n",
      "10000250.csv\n",
      "10000251.csv\n",
      "10000252.csv\n",
      "10000253.csv\n",
      "10000254.csv\n",
      "10000255.csv\n",
      "10000256.csv\n",
      "10000257.csv\n",
      "10000258.csv\n",
      "10000259.csv\n",
      "10000260.csv\n",
      "10000261.csv\n",
      "10000262.csv\n",
      "10000263.csv\n",
      "10000264.csv\n",
      "10000265.csv\n",
      "10000266.csv\n",
      "10000267.csv\n",
      "10000268.csv\n",
      "10000269.csv\n",
      "10000270.csv\n",
      "10000271.csv\n",
      "10000272.csv\n",
      "10000273.csv\n",
      "10000274.csv\n",
      "10000275.csv\n",
      "10000276.csv\n",
      "10000277.csv\n",
      "10000278.csv\n",
      "10000279.csv\n",
      "10000280.csv\n",
      "10000281.csv\n",
      "10000282.csv\n",
      "10000283.csv\n",
      "10000284.csv\n",
      "10000285.csv\n",
      "10000286.csv\n",
      "10000287.csv\n",
      "10000288.csv\n",
      "10000289.csv\n",
      "10000290.csv\n",
      "10000291.csv\n",
      "10000292.csv\n",
      "10000293.csv\n",
      "10000294.csv\n",
      "10000295.csv\n",
      "10000296.csv\n",
      "10000297.csv\n",
      "10000298.csv\n",
      "10000299.csv\n",
      "10000300.csv\n",
      "10000301.csv\n",
      "10000302.csv\n",
      "10000303.csv\n",
      "10000304.csv\n",
      "10000305.csv\n",
      "10000306.csv\n",
      "10000307.csv\n",
      "10000308.csv\n",
      "10000309.csv\n",
      "10000310.csv\n",
      "10000311.csv\n",
      "10000312.csv\n",
      "10000313.csv\n",
      "10000314.csv\n",
      "10000315.csv\n",
      "10000316.csv\n",
      "10000317.csv\n",
      "10000318.csv\n",
      "10000319.csv\n",
      "10000320.csv\n",
      "10000321.csv\n",
      "10000322.csv\n",
      "10000323.csv\n",
      "10000324.csv\n",
      "10000325.csv\n",
      "10000326.csv\n",
      "10000327.csv\n",
      "10000328.csv\n",
      "10000329.csv\n",
      "10000330.csv\n",
      "10000331.csv\n",
      "10000332.csv\n",
      "10000333.csv\n",
      "10000334.csv\n",
      "10000335.csv\n",
      "10000336.csv\n",
      "10000337.csv\n",
      "10000338.csv\n",
      "10000339.csv\n",
      "10000340.csv\n",
      "10000341.csv\n",
      "10000342.csv\n",
      "10000343.csv\n",
      "10000344.csv\n",
      "10000345.csv\n",
      "10000346.csv\n",
      "10000347.csv\n",
      "10000348.csv\n",
      "10000349.csv\n",
      "10000350.csv\n",
      "10000351.csv\n",
      "10000352.csv\n",
      "10000353.csv\n",
      "10000354.csv\n",
      "10000355.csv\n",
      "10000356.csv\n",
      "10000357.csv\n",
      "10000358.csv\n",
      "10000359.csv\n",
      "10000360.csv\n",
      "10000361.csv\n",
      "10000362.csv\n",
      "10000363.csv\n",
      "10000364.csv\n",
      "10000365.csv\n",
      "10000366.csv\n",
      "10000367.csv\n",
      "10000368.csv\n",
      "10000369.csv\n",
      "10000370.csv\n",
      "10000371.csv\n",
      "10000372.csv\n",
      "10000373.csv\n",
      "10000374.csv\n",
      "10000375.csv\n",
      "10000376.csv\n",
      "10000377.csv\n",
      "10000378.csv\n",
      "10000379.csv\n",
      "10000380.csv\n",
      "10000381.csv\n",
      "10000382.csv\n",
      "10000383.csv\n",
      "10000384.csv\n",
      "10000385.csv\n",
      "10000386.csv\n",
      "10000387.csv\n",
      "10000388.csv\n",
      "10000389.csv\n",
      "10000390.csv\n",
      "10000391.csv\n",
      "10000392.csv\n",
      "10000393.csv\n",
      "10000394.csv\n",
      "10000395.csv\n",
      "10000396.csv\n",
      "10000397.csv\n",
      "10000398.csv\n",
      "10000399.csv\n",
      "10000400.csv\n",
      "10000401.csv\n",
      "10000402.csv\n",
      "10000403.csv\n",
      "10000404.csv\n",
      "10000405.csv\n",
      "10000406.csv\n",
      "10000407.csv\n",
      "10000408.csv\n",
      "10000409.csv\n",
      "10000410.csv\n",
      "10000411.csv\n",
      "10000412.csv\n",
      "10000413.csv\n",
      "10000414.csv\n",
      "10000415.csv\n",
      "10000416.csv\n",
      "10000417.csv\n",
      "10000418.csv\n",
      "10000419.csv\n",
      "10000420.csv\n",
      "10000421.csv\n",
      "10000422.csv\n",
      "10000423.csv\n",
      "10000424.csv\n",
      "10000425.csv\n",
      "10000426.csv\n",
      "10000427.csv\n",
      "10000428.csv\n",
      "10000429.csv\n",
      "10000430.csv\n",
      "10000431.csv\n",
      "10000432.csv\n",
      "10000433.csv\n",
      "10000434.csv\n",
      "10000435.csv\n",
      "10000436.csv\n",
      "10000437.csv\n",
      "10000438.csv\n",
      "10000439.csv\n",
      "10000440.csv\n",
      "10000441.csv\n",
      "10000442.csv\n",
      "10000443.csv\n",
      "10000444.csv\n",
      "10000445.csv\n",
      "10000446.csv\n",
      "10000447.csv\n",
      "10000448.csv\n",
      "10000449.csv\n",
      "10000450.csv\n",
      "10000451.csv\n",
      "10000452.csv\n",
      "10000453.csv\n",
      "10000454.csv\n",
      "10000455.csv\n",
      "10000456.csv\n",
      "10000457.csv\n",
      "10000458.csv\n",
      "10000459.csv\n",
      "10000460.csv\n",
      "10000461.csv\n",
      "10000462.csv\n",
      "10000463.csv\n",
      "10000464.csv\n",
      "10000465.csv\n",
      "10000466.csv\n",
      "10000467.csv\n",
      "10000468.csv\n",
      "10000469.csv\n",
      "10000470.csv\n",
      "10000471.csv\n",
      "10000472.csv\n",
      "10000473.csv\n",
      "10000474.csv\n",
      "10000475.csv\n",
      "10000476.csv\n",
      "10000477.csv\n",
      "10000478.csv\n",
      "10000479.csv\n",
      "10000480.csv\n",
      "10000481.csv\n",
      "10000482.csv\n",
      "10000483.csv\n",
      "10000484.csv\n",
      "10000485.csv\n",
      "10000486.csv\n",
      "10000487.csv\n",
      "10000488.csv\n",
      "10000489.csv\n",
      "10000490.csv\n",
      "10000491.csv\n",
      "10000492.csv\n",
      "10000493.csv\n",
      "10000494.csv\n",
      "10000495.csv\n",
      "10000496.csv\n",
      "10000497.csv\n",
      "10000498.csv\n",
      "10000499.csv\n",
      "10000500.csv\n",
      "10000501.csv\n",
      "10000502.csv\n",
      "10000503.csv\n",
      "10000504.csv\n",
      "10000505.csv\n",
      "10000506.csv\n",
      "10000507.csv\n",
      "10000508.csv\n",
      "10000509.csv\n",
      "10000510.csv\n",
      "10000511.csv\n",
      "10000512.csv\n",
      "10000513.csv\n",
      "10000514.csv\n",
      "10000515.csv\n",
      "10000516.csv\n",
      "10000517.csv\n",
      "10000518.csv\n",
      "10000519.csv\n",
      "10000520.csv\n",
      "10000521.csv\n",
      "10000522.csv\n",
      "10000523.csv\n",
      "10000524.csv\n",
      "10000525.csv\n",
      "10000526.csv\n",
      "10000527.csv\n",
      "10000528.csv\n",
      "10000529.csv\n",
      "10000530.csv\n",
      "10000531.csv\n",
      "10000532.csv\n",
      "10000533.csv\n",
      "10000534.csv\n",
      "10000535.csv\n",
      "10000536.csv\n",
      "10000537.csv\n",
      "10000538.csv\n",
      "10000539.csv\n",
      "10000540.csv\n",
      "10000541.csv\n",
      "10000542.csv\n",
      "10000543.csv\n",
      "10000544.csv\n",
      "10000545.csv\n",
      "10000546.csv\n",
      "10000547.csv\n",
      "10000548.csv\n",
      "10000549.csv\n",
      "10000550.csv\n",
      "10000551.csv\n",
      "10000552.csv\n",
      "10000553.csv\n",
      "10000554.csv\n",
      "10000555.csv\n",
      "10000556.csv\n",
      "10000557.csv\n",
      "10000558.csv\n",
      "10000559.csv\n",
      "10000560.csv\n",
      "10000561.csv\n",
      "10000562.csv\n",
      "10000563.csv\n",
      "10000564.csv\n",
      "10000565.csv\n",
      "10000566.csv\n",
      "10000567.csv\n",
      "10000568.csv\n",
      "10000569.csv\n",
      "10000570.csv\n",
      "10000571.csv\n",
      "10000572.csv\n",
      "10000573.csv\n",
      "10000574.csv\n",
      "10000575.csv\n",
      "10000576.csv\n",
      "10000577.csv\n",
      "10000578.csv\n",
      "10000579.csv\n",
      "10000580.csv\n",
      "10000581.csv\n",
      "10000582.csv\n",
      "10000583.csv\n",
      "10000584.csv\n",
      "10000585.csv\n",
      "10000586.csv\n",
      "10000587.csv\n",
      "10000588.csv\n",
      "10000589.csv\n",
      "10000590.csv\n",
      "10000591.csv\n",
      "10000592.csv\n",
      "10000593.csv\n",
      "10000594.csv\n",
      "10000595.csv\n",
      "10000596.csv\n",
      "10000597.csv\n",
      "10000598.csv\n",
      "10000599.csv\n",
      "10000600.csv\n",
      "10000601.csv\n",
      "10000602.csv\n",
      "10000603.csv\n",
      "10000604.csv\n",
      "10000605.csv\n",
      "10000606.csv\n",
      "10000607.csv\n",
      "10000608.csv\n",
      "10000609.csv\n",
      "10000610.csv\n",
      "10000611.csv\n",
      "10000612.csv\n",
      "10000613.csv\n",
      "10000614.csv\n",
      "10000615.csv\n",
      "10000616.csv\n",
      "10000617.csv\n",
      "10000618.csv\n",
      "10000619.csv\n",
      "10000620.csv\n",
      "10000621.csv\n",
      "10000622.csv\n",
      "10000623.csv\n",
      "10000624.csv\n",
      "10000625.csv\n",
      "10000626.csv\n",
      "10000627.csv\n",
      "10000628.csv\n",
      "10000629.csv\n",
      "10000630.csv\n",
      "10000631.csv\n",
      "10000632.csv\n",
      "10000633.csv\n",
      "10000634.csv\n",
      "10000635.csv\n",
      "10000636.csv\n",
      "10000637.csv\n",
      "10000638.csv\n",
      "10000639.csv\n",
      "10000640.csv\n",
      "10000641.csv\n",
      "10000642.csv\n",
      "10000643.csv\n",
      "10000644.csv\n",
      "10000645.csv\n",
      "10000646.csv\n",
      "10000647.csv\n",
      "10000648.csv\n",
      "10000649.csv\n",
      "10000650.csv\n",
      "10000651.csv\n",
      "10000652.csv\n",
      "10000653.csv\n",
      "10000654.csv\n",
      "10000655.csv\n",
      "10000656.csv\n",
      "10000657.csv\n",
      "10000658.csv\n",
      "10000659.csv\n",
      "10000660.csv\n",
      "10000661.csv\n",
      "10000662.csv\n",
      "10000663.csv\n",
      "10000664.csv\n",
      "10000665.csv\n",
      "10000666.csv\n",
      "10000667.csv\n",
      "10000668.csv\n",
      "10000669.csv\n",
      "10000670.csv\n",
      "10000671.csv\n",
      "10000672.csv\n",
      "10000673.csv\n",
      "10000674.csv\n",
      "10000675.csv\n",
      "10000676.csv\n",
      "10000677.csv\n",
      "10000678.csv\n",
      "10000679.csv\n",
      "10000680.csv\n",
      "10000681.csv\n",
      "10000682.csv\n",
      "10000683.csv\n",
      "10000684.csv\n",
      "10000685.csv\n",
      "10000686.csv\n",
      "10000687.csv\n",
      "10000688.csv\n",
      "10000689.csv\n",
      "10000690.csv\n",
      "10000691.csv\n",
      "10000692.csv\n",
      "10000693.csv\n",
      "10000694.csv\n",
      "10000695.csv\n",
      "10000696.csv\n",
      "10000697.csv\n",
      "10000698.csv\n",
      "10000699.csv\n",
      "10000700.csv\n",
      "10000701.csv\n",
      "10000702.csv\n",
      "10000703.csv\n",
      "10000704.csv\n",
      "10000705.csv\n",
      "10000706.csv\n",
      "10000707.csv\n",
      "10000708.csv\n",
      "10000709.csv\n",
      "10000710.csv\n",
      "10000711.csv\n",
      "10000712.csv\n",
      "10000713.csv\n",
      "10000714.csv\n",
      "10000715.csv\n",
      "10000716.csv\n",
      "10000717.csv\n",
      "10000718.csv\n",
      "10000719.csv\n",
      "10000720.csv\n",
      "10000721.csv\n",
      "10000722.csv\n",
      "10000723.csv\n",
      "10000724.csv\n",
      "10000725.csv\n",
      "10000726.csv\n",
      "10000727.csv\n",
      "10000728.csv\n",
      "10000729.csv\n",
      "10000730.csv\n",
      "10000731.csv\n",
      "10000732.csv\n",
      "10000733.csv\n",
      "10000734.csv\n",
      "10000735.csv\n",
      "10000736.csv\n",
      "10000737.csv\n",
      "10000738.csv\n",
      "10000739.csv\n",
      "10000740.csv\n",
      "10000741.csv\n",
      "10000742.csv\n",
      "10000743.csv\n",
      "10000744.csv\n",
      "10000745.csv\n",
      "10000746.csv\n",
      "10000747.csv\n",
      "10000748.csv\n",
      "10000749.csv\n",
      "10000750.csv\n",
      "10000751.csv\n",
      "10000752.csv\n",
      "10000753.csv\n",
      "10000754.csv\n",
      "10000755.csv\n",
      "10000756.csv\n",
      "10000757.csv\n",
      "10000758.csv\n",
      "10000759.csv\n",
      "10000760.csv\n",
      "10000761.csv\n",
      "10000762.csv\n",
      "10000763.csv\n",
      "10000764.csv\n",
      "10000765.csv\n",
      "10000766.csv\n",
      "10000767.csv\n",
      "10000768.csv\n",
      "10000769.csv\n",
      "10000770.csv\n",
      "10000771.csv\n",
      "10000772.csv\n",
      "10000773.csv\n",
      "10000774.csv\n",
      "10000775.csv\n",
      "10000776.csv\n",
      "10000777.csv\n",
      "10000778.csv\n",
      "10000779.csv\n",
      "10000780.csv\n",
      "10000781.csv\n",
      "10000782.csv\n",
      "10000783.csv\n",
      "10000784.csv\n",
      "10000785.csv\n",
      "10000786.csv\n",
      "10000787.csv\n",
      "10000788.csv\n",
      "10000789.csv\n",
      "10000790.csv\n",
      "10000791.csv\n",
      "10000792.csv\n",
      "10000793.csv\n",
      "10000794.csv\n",
      "10000795.csv\n",
      "10000796.csv\n",
      "10000797.csv\n",
      "10000798.csv\n",
      "10000799.csv\n",
      "10000800.csv\n",
      "10000801.csv\n",
      "10000802.csv\n",
      "10000803.csv\n",
      "10000804.csv\n",
      "10000805.csv\n",
      "10000806.csv\n",
      "10000807.csv\n",
      "10000808.csv\n",
      "10000809.csv\n",
      "10000810.csv\n",
      "10000811.csv\n",
      "10000812.csv\n",
      "10000813.csv\n",
      "10000814.csv\n",
      "10000815.csv\n",
      "10000816.csv\n",
      "10000817.csv\n",
      "10000818.csv\n",
      "10000819.csv\n",
      "10000820.csv\n",
      "10000821.csv\n",
      "10000822.csv\n",
      "10000823.csv\n",
      "10000824.csv\n",
      "10000825.csv\n",
      "10000826.csv\n",
      "10000827.csv\n",
      "10000828.csv\n",
      "10000829.csv\n",
      "10000830.csv\n",
      "10000831.csv\n",
      "10000832.csv\n",
      "10000833.csv\n",
      "10000834.csv\n",
      "10000835.csv\n",
      "10000836.csv\n",
      "10000837.csv\n",
      "10000838.csv\n",
      "10000839.csv\n",
      "10000840.csv\n",
      "10000841.csv\n",
      "10000842.csv\n",
      "10000843.csv\n",
      "10000844.csv\n",
      "10000845.csv\n",
      "10000846.csv\n",
      "10000847.csv\n",
      "10000848.csv\n",
      "10000849.csv\n",
      "10000850.csv\n",
      "10000851.csv\n",
      "10000852.csv\n",
      "10000853.csv\n",
      "10000854.csv\n",
      "10000855.csv\n",
      "10000856.csv\n",
      "10000857.csv\n",
      "10000858.csv\n",
      "10000859.csv\n",
      "10000860.csv\n",
      "10000861.csv\n",
      "10000862.csv\n",
      "10000863.csv\n",
      "10000864.csv\n",
      "10000865.csv\n",
      "10000866.csv\n",
      "10000867.csv\n",
      "10000868.csv\n",
      "10000869.csv\n",
      "10000870.csv\n",
      "10000871.csv\n",
      "10000872.csv\n",
      "10000873.csv\n",
      "10000874.csv\n",
      "10000875.csv\n",
      "10000876.csv\n",
      "10000877.csv\n",
      "10000878.csv\n",
      "10000879.csv\n",
      "10000880.csv\n",
      "10000881.csv\n",
      "10000882.csv\n",
      "10000883.csv\n",
      "10000884.csv\n",
      "10000885.csv\n",
      "10000886.csv\n",
      "10000887.csv\n",
      "10000888.csv\n",
      "10000889.csv\n",
      "10000890.csv\n",
      "10000891.csv\n",
      "10000892.csv\n",
      "10000893.csv\n",
      "10000894.csv\n",
      "10000895.csv\n",
      "10000896.csv\n",
      "10000897.csv\n",
      "10000898.csv\n",
      "10000899.csv\n",
      "10000900.csv\n",
      "10000901.csv\n",
      "10000902.csv\n",
      "10000903.csv\n",
      "10000904.csv\n",
      "10000905.csv\n",
      "10000906.csv\n",
      "10000907.csv\n",
      "10000908.csv\n",
      "10000909.csv\n",
      "10000910.csv\n",
      "10000911.csv\n",
      "10000912.csv\n",
      "10000913.csv\n",
      "10000914.csv\n",
      "10000915.csv\n",
      "10000916.csv\n",
      "10000917.csv\n",
      "10000918.csv\n",
      "10000919.csv\n",
      "10000920.csv\n",
      "10000921.csv\n",
      "10000922.csv\n",
      "10000923.csv\n",
      "10000924.csv\n",
      "10000925.csv\n",
      "10000926.csv\n",
      "10000927.csv\n",
      "10000928.csv\n",
      "10000929.csv\n",
      "10000930.csv\n",
      "10000931.csv\n",
      "10000932.csv\n",
      "10000933.csv\n",
      "10000934.csv\n",
      "10000935.csv\n",
      "10000936.csv\n",
      "10000937.csv\n",
      "10000938.csv\n",
      "10000939.csv\n",
      "10000940.csv\n",
      "10000941.csv\n",
      "10000942.csv\n",
      "10000943.csv\n",
      "10000944.csv\n",
      "10000945.csv\n",
      "10000946.csv\n",
      "10000947.csv\n",
      "10000948.csv\n",
      "10000949.csv\n",
      "10000950.csv\n",
      "10000951.csv\n",
      "10000952.csv\n",
      "10000953.csv\n",
      "10000954.csv\n",
      "10000955.csv\n",
      "10000956.csv\n",
      "10000957.csv\n",
      "10000958.csv\n",
      "10000959.csv\n",
      "10000960.csv\n",
      "10000961.csv\n",
      "10000962.csv\n",
      "10000963.csv\n",
      "10000964.csv\n",
      "10000965.csv\n",
      "10000966.csv\n",
      "10000967.csv\n",
      "10000968.csv\n",
      "10000969.csv\n",
      "10000970.csv\n",
      "10000971.csv\n",
      "10000972.csv\n",
      "10000973.csv\n",
      "10000974.csv\n",
      "10000975.csv\n",
      "10000976.csv\n",
      "10000977.csv\n",
      "10000978.csv\n",
      "10000979.csv\n",
      "10000980.csv\n",
      "10000981.csv\n",
      "10000982.csv\n",
      "10000983.csv\n",
      "10000984.csv\n",
      "10000985.csv\n",
      "10000986.csv\n",
      "10000987.csv\n",
      "10000988.csv\n",
      "10000989.csv\n",
      "10000990.csv\n",
      "10000991.csv\n",
      "10000992.csv\n",
      "10000993.csv\n",
      "10000994.csv\n",
      "10000995.csv\n",
      "10000996.csv\n",
      "10000997.csv\n",
      "10000998.csv\n",
      "10000999.csv\n",
      "10001000.csv\n",
      "10001001.csv\n",
      "10001002.csv\n",
      "10001003.csv\n",
      "10001004.csv\n",
      "10001005.csv\n",
      "10001006.csv\n",
      "10001007.csv\n",
      "10001008.csv\n",
      "10001009.csv\n",
      "10001010.csv\n",
      "10001011.csv\n",
      "10001012.csv\n",
      "10001013.csv\n",
      "10001014.csv\n",
      "10001015.csv\n",
      "10001016.csv\n",
      "10001017.csv\n",
      "10001018.csv\n",
      "10001019.csv\n",
      "10001020.csv\n",
      "10001021.csv\n",
      "10001022.csv\n",
      "10001023.csv\n",
      "10001024.csv\n",
      "10001025.csv\n",
      "10001026.csv\n",
      "10001027.csv\n",
      "10001028.csv\n",
      "10001029.csv\n",
      "10001030.csv\n",
      "10001031.csv\n",
      "10001032.csv\n",
      "10001033.csv\n",
      "10001034.csv\n",
      "10001035.csv\n",
      "10001036.csv\n",
      "10001037.csv\n",
      "10001038.csv\n",
      "10001039.csv\n",
      "10001040.csv\n",
      "10001041.csv\n",
      "10001042.csv\n",
      "10001043.csv\n",
      "10001044.csv\n",
      "10001045.csv\n",
      "10001046.csv\n",
      "10001047.csv\n",
      "10001048.csv\n",
      "10001049.csv\n",
      "10001050.csv\n",
      "10001051.csv\n",
      "10001052.csv\n",
      "10001053.csv\n",
      "10001054.csv\n",
      "10001055.csv\n",
      "10001056.csv\n",
      "10001057.csv\n",
      "10001058.csv\n",
      "10001059.csv\n",
      "10001060.csv\n",
      "10001061.csv\n",
      "10001062.csv\n",
      "10001063.csv\n",
      "10001064.csv\n",
      "10001065.csv\n",
      "10001066.csv\n",
      "10001067.csv\n",
      "10001068.csv\n",
      "10001069.csv\n",
      "10001070.csv\n",
      "10001071.csv\n",
      "10001072.csv\n",
      "10001073.csv\n",
      "10001074.csv\n",
      "10001075.csv\n",
      "10001076.csv\n",
      "10001077.csv\n",
      "10001078.csv\n",
      "10001079.csv\n",
      "10001080.csv\n",
      "10001081.csv\n",
      "10001082.csv\n",
      "10001083.csv\n",
      "10001084.csv\n",
      "10001085.csv\n",
      "10001086.csv\n",
      "10001087.csv\n",
      "10001088.csv\n",
      "10001089.csv\n",
      "10001090.csv\n",
      "10001091.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-13-5e7ba2163e27>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[0mll\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m1139\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;32mfor\u001B[0m \u001B[0mcsv_name\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mcsv_list\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 18\u001B[1;33m     \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcsv_name\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     19\u001B[0m     \u001B[0mll\u001B[0m \u001B[1;33m-=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     20\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mll\u001B[0m \u001B[1;33m>\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\iostream.py\u001B[0m in \u001B[0;36mwrite\u001B[1;34m(self, string)\u001B[0m\n\u001B[0;32m    350\u001B[0m             \u001B[0mis_child\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;32mnot\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_is_master_process\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    351\u001B[0m             \u001B[1;31m# only touch the buffer in the IO thread to avoid races\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 352\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpub_thread\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mschedule\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[1;33m:\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_buffer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mwrite\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstring\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    353\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mis_child\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    354\u001B[0m                 \u001B[1;31m# newlines imply flush in subprocesses\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\ipykernel\\iostream.py\u001B[0m in \u001B[0;36mschedule\u001B[1;34m(self, f)\u001B[0m\n\u001B[0;32m    188\u001B[0m                 \u001B[0mevent_id\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mos\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0murandom\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;36m16\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    189\u001B[0m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_events\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mevent_id\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 190\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_event_pipe\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevent_id\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    191\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    192\u001B[0m             \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mzmq/backend/cython/socket.pyx\u001B[0m in \u001B[0;36mzmq.backend.cython.socket.Socket.send (zmq\\backend\\cython\\socket.c:7305)\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mzmq/backend/cython/socket.pyx\u001B[0m in \u001B[0;36mzmq.backend.cython.socket.Socket.send (zmq\\backend\\cython\\socket.c:7048)\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mzmq/backend/cython/socket.pyx\u001B[0m in \u001B[0;36mzmq.backend.cython.socket._send_copy (zmq\\backend\\cython\\socket.c:2920)\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001B[0m in \u001B[0;36mzmq.backend.cython.checkrc._check_rc (zmq\\backend\\cython\\socket.c:9621)\u001B[1;34m()\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#数据处理\n",
    "alldata = []\n",
    "rate = pd.read_excel(r\".\\data\\unrisked_rate.xlsx\")\n",
    "rate['date'] = pd.to_datetime(rate['date'])\n",
    "rate['Value'] = rate['Value']/100\n",
    "\n",
    "etf50 = pd.read_excel(r'.\\data\\50etf_df.xlsx')\n",
    "etf50 = etf50[['Date','close']]\n",
    "etf50['Date'] = pd.to_datetime(etf50['Date'])\n",
    "\n",
    "csv_folder = r'.\\data\\50etf_option_data_csv'\n",
    "output_folder = r'.\\data\\out'\n",
    "csv_list = os.listdir(csv_folder)\n",
    "\n",
    "# ll = 1139\n",
    "for csv_name in csv_list:\n",
    "    print(csv_name)\n",
    "    '''ll -= 1\n",
    "    if ll > 0:\n",
    "        continue'''\n",
    "    perdata = []\n",
    "    csv_path = csv_folder +\"\\\\\"+csv_name\n",
    "    output_path = output_folder + \"\\\\\" + csv_name\n",
    "    data = pd.read_csv(csv_path, encoding = 'GBK', index_col= False)\n",
    "\n",
    "    data = data[['date','ptmtradeday','exe_price', 'open', 'high','low','close', 'call_or_put']]\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    data['call_or_put'] = data['call_or_put'].apply(change)\n",
    "    if data['open'].dtype == 'object':\n",
    "        data.drop(data[data.open == '非数字'].index, inplace=True)\n",
    "\n",
    "    merged_option1 = pd.merge(rate, data, on = 'date', how = 'inner')\n",
    "    merged_option2 = pd.merge(etf50, merged_option1, left_on = 'Date', right_on = 'date', how = 'inner')\n",
    "    merged_option2 = merged_option2[['call_or_put','date','ptmtradeday','exe_price','Value', 'open', 'high','low','close_y','close_x']]\n",
    "    merged_option2.columns = ['call_or_put', 'date','ptmtradeday','k', 'rate', 'open', 'high','low','close','s']\n",
    "\n",
    "    for i in range(merged_option2.shape[0]):\n",
    "        merged_option2['close'][i] = float(merged_option2['close'][i])\n",
    "        tmp = iv_bs_bisection(np.array(merged_option2['s'][i]), np.array(merged_option2['k'][i]), np.array(merged_option2['rate'][i]), np.array(merged_option2['ptmtradeday'][i]), np.array(merged_option2['close'][i]), np.array(merged_option2['call_or_put'][i]))\n",
    "        if abs(tmp - 0.985) < 0.005 or abs(tmp - 0.015) < 0.005 or abs(tmp - 0.5) < 0.005:\n",
    "            if i == 0:\n",
    "                tmp = tmp\n",
    "            else:\n",
    "                tmp = perdata[i-1] + random.random()/100 - 0.005\n",
    "\n",
    "        perdata.append(tmp)\n",
    "\n",
    "    merged_option2['iv'] = perdata\n",
    "    merged_option2.to_csv(output_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000100.csv\n",
      "10000200.csv\n",
      "10000300.csv\n",
      "10000400.csv\n",
      "10000500.csv\n",
      "10000600.csv\n",
      "10000700.csv\n",
      "10000800.csv\n",
      "10000900.csv\n",
      "10001000.csv\n",
      "10001100.csv\n",
      "10001200.csv\n",
      "10001300.csv\n",
      "10001400.csv\n",
      "10001500.csv\n",
      "10001600.csv\n",
      "10001700.csv\n",
      "10001800.csv\n",
      "10001900.csv\n",
      "10002000.csv\n",
      "10002100.csv\n",
      "10002200.csv\n"
     ]
    }
   ],
   "source": [
    "#拼训练数据\n",
    "csv_folder = r'.\\data\\out'\n",
    "output_folder = r'.\\data'\n",
    "csv_list = os.listdir(csv_folder)\n",
    "output_path = output_folder + \"\\\\\" + 'final_data.csv'\n",
    "\n",
    "call_X = []\n",
    "call_Y = []\n",
    "put_X = []\n",
    "put_Y = []\n",
    "# 加一个混合\n",
    "# 做一个对比\n",
    "\n",
    "#numbers = 1139\n",
    "\n",
    "for csv_name in csv_list:\n",
    "    if int(csv_name.split('.')[0]) % 100 == 0:\n",
    "        print(csv_name)\n",
    "    perdata = []\n",
    "    '''numbers -= 1\n",
    "    if numbers == 0:\n",
    "        break'''\n",
    "    csv_path = csv_folder +\"\\\\\"+csv_name\n",
    "    data = pd.read_csv(csv_path, encoding = 'GBK', index_col= False)\n",
    "    if len(data) < 11:\n",
    "        continue\n",
    "\n",
    "    datatype = data['call_or_put'][0]\n",
    "    ll = 0\n",
    "\n",
    "    for i in range(len(data)-1):\n",
    "        onedata = list(data.iloc[i,3:])\n",
    "        perdata.append(onedata)\n",
    "        ll += 1\n",
    "        if ll == 10:\n",
    "            if datatype == 'call':\n",
    "                call_X.append(perdata)\n",
    "                call_Y.append(data['iv'][i+1])\n",
    "            else:\n",
    "                put_X.append(perdata)\n",
    "                put_Y.append(data['iv'][i+1])\n",
    "            ll -= 1\n",
    "            perdata = perdata[1:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100100\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "teststring = '100100.csv'\n",
    "print(teststring.split('.')[0])\n",
    "print(int(teststring.split('.')[0]) % 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12075 0.00286393148233\n",
      "12076 3.59737517164e-05\n",
      "12077 0.00297874411765\n",
      "12078 0.000318559103993\n",
      "12092 0.00410451302802\n",
      "12093 0.00225836145527\n",
      "12095 0.00184864933953\n",
      "26088 0.00244463288221\n",
      "26089 0.00411922363615\n",
      "26090 0.00630291729092\n",
      "26091 0.0105671176137\n",
      "26092 0.0112089789661\n",
      "26093 0.00858699003753\n",
      "26094 0.00398529588666\n",
      "26096 0.00455974837495\n",
      "26097 0.00887373301837\n",
      "26098 0.0114674415614\n",
      "26099 0.0094961026026\n",
      "26100 0.00860402921986\n",
      "26101 0.00463112669689\n",
      "26102 0.00416382105174\n",
      "26103 0.00505357421686\n",
      "26104 0.010027647453\n",
      "26105 0.00749296630298\n",
      "26106 0.00698461148705\n",
      "26107 0.00526612688848\n",
      "26108 0.00966071213234\n",
      "26109 0.0109322635728\n",
      "26110 0.00801595809705\n",
      "26111 0.00333193738274\n",
      "26112 0.00212004144553\n",
      "26113 0.00591131100696\n",
      "26114 0.00467923608703\n",
      "26115 0.00212724501505\n",
      "26117 0.00153714700592\n",
      "26118 0.00277143473715\n",
      "26866 0.00555057445115\n",
      "26867 0.00880277866473\n",
      "26868 0.00617870925902\n",
      "26869 0.00717230586553\n",
      "26870 0.0112993984634\n",
      "26871 0.0145154916113\n",
      "26872 0.0111374406934\n",
      "26873 0.0103711571614\n",
      "26874 0.00883079140899\n",
      "26875 0.0121937730318\n",
      "26876 0.0134243808125\n",
      "26877 0.0104119976067\n",
      "26878 0.00777994255329\n",
      "26879 0.0107474091323\n",
      "26880 0.00787134876925\n",
      "26881 0.00544562902741\n",
      "26882 0.00244043765668\n",
      "26883 0.00689330194536\n",
      "26884 0.00213034560454\n",
      "26885 0.00248525604712\n",
      "26886 0.00688178699521\n",
      "26887 0.00993469635686\n",
      "26888 0.00797259210032\n",
      "26889 0.00455382740894\n",
      "26890 0.00316964653809\n",
      "26892 0.000763863553893\n",
      "26894 0.000854128562688\n",
      "26900 0.00154406223365\n",
      "26901 0.00540567413126\n",
      "26902 0.00250060163422\n",
      "26903 0.0069604972654\n",
      "26904 0.0111760863048\n",
      "26905 0.0145891049325\n",
      "26906 0.0168730505246\n",
      "26907 0.0194909370854\n",
      "26908 0.0198308073139\n",
      "26909 0.0184984443488\n",
      "26910 0.0171096736144\n",
      "67121 0.000728140990011\n",
      "67122 0.000474431754403\n"
     ]
    }
   ],
   "source": [
    "call_X = np.array(call_X)\n",
    "call_Y = np.array(call_Y)\n",
    "\n",
    "put_X = np.array(put_X)\n",
    "put_Y = np.array(put_Y)\n",
    "\n",
    "# 数据处理\n",
    "for i in range(len(call_X)):\n",
    "    if call_Y[i] <= 0:\n",
    "        call_Y[i] = -call_Y[i]\n",
    "        print(i, call_Y[i])\n",
    "    for j in range(10):\n",
    "        for k in range(1, 9):\n",
    "            if call_X[i][j][k] <= 0:\n",
    "                call_X[i][j][k] = -call_X[i][j][k]\n",
    "                print(i,j,k,call_X[i][j][k])\n",
    "\n",
    "for i in range(len(put_X)):\n",
    "    if put_Y[i] <= 0:\n",
    "        put_Y[i] = -put_Y[i]\n",
    "        print(i, put_Y[i])\n",
    "    for j in range(10):\n",
    "        for k in range(1, 9):\n",
    "            if put_X[i][j][k] <= 0:\n",
    "                put_X[i][j][k] = -put_X[i][j][k]\n",
    "                print(i,j,k,put_X[i][j][k])\n",
    "# 正则化\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "call_train_X, call_val_X, call_train_Y, call_val_Y = train_test_split(call_X,\n",
    "                                                                      call_Y,\n",
    "                                                                      test_size=0.2,\n",
    "                                                                      random_state=19011)\n",
    "\n",
    "put_train_X, put_val_X, put_train_Y, put_val_Y = train_test_split(put_X,\n",
    "                                                                  put_Y,\n",
    "                                                                  test_size=0.2,\n",
    "                                                                  random_state=19011)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_37 (Conv1D)           (None, 9, 32)             608       \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 8, 64)             4160      \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 7, 128)            16512     \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 6, 256)            65792     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 1537      \n",
      "=================================================================\n",
      "Total params: 88,609\n",
      "Trainable params: 88,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5000 samples, validate on 50 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 2/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 3/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 4/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 5/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 6/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 7/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 8/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 9/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 10/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 11/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 12/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 13/50\n",
      " - 3s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 14/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-18-a8863b8c2651>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     34\u001B[0m                     \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcall_val_X\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m150\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcall_val_Y\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m150\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m                     \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m                     shuffle=False)\n\u001B[0m\u001B[0;32m     37\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001B[0m\n\u001B[0;32m    961\u001B[0m                               \u001B[0minitial_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minitial_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    962\u001B[0m                               \u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 963\u001B[1;33m                               validation_steps=validation_steps)\n\u001B[0m\u001B[0;32m    964\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    965\u001B[0m     def evaluate(self, x=None, y=None,\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001B[0m\n\u001B[0;32m   1703\u001B[0m                               \u001B[0minitial_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minitial_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1704\u001B[0m                               \u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1705\u001B[1;33m                               validation_steps=validation_steps)\n\u001B[0m\u001B[0;32m   1706\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1707\u001B[0m     def evaluate(self, x=None, y=None,\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_fit_loop\u001B[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001B[0m\n\u001B[0;32m   1233\u001B[0m                         \u001B[0mins_batch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mins_batch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1234\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1235\u001B[1;33m                     \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mins_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1236\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mouts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1237\u001B[0m                         \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mouts\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   2476\u001B[0m         \u001B[0msession\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_session\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2477\u001B[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001B[1;32m-> 2478\u001B[1;33m                               **self.session_kwargs)\n\u001B[0m\u001B[0;32m   2479\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mupdated\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m    898\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    899\u001B[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001B[1;32m--> 900\u001B[1;33m                          run_metadata_ptr)\n\u001B[0m\u001B[0;32m    901\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    902\u001B[0m         \u001B[0mproto_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_GetBuffer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrun_metadata_ptr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_run\u001B[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1133\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mfinal_fetches\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mfinal_targets\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mhandle\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mfeed_dict_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1134\u001B[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001B[1;32m-> 1135\u001B[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001B[0m\u001B[0;32m   1136\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1137\u001B[0m       \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_do_run\u001B[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1314\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhandle\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1315\u001B[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001B[1;32m-> 1316\u001B[1;33m                            run_metadata)\n\u001B[0m\u001B[0;32m   1317\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1318\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_prun_fn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeeds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfetches\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_do_call\u001B[1;34m(self, fn, *args)\u001B[0m\n\u001B[0;32m   1320\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_do_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1321\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1322\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1323\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOpError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1324\u001B[0m       \u001B[0mmessage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_run_fn\u001B[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[0;32m   1305\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_extend_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1306\u001B[0m       return self._call_tf_sessionrun(\n\u001B[1;32m-> 1307\u001B[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001B[0m\u001B[0;32m   1308\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1309\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_prun_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeed_dict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfetch_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_call_tf_sessionrun\u001B[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[0;32m   1407\u001B[0m       return tf_session.TF_SessionRun_wrapper(\n\u001B[0;32m   1408\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_session\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeed_dict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfetch_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget_list\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1409\u001B[1;33m           run_metadata)\n\u001B[0m\u001B[0;32m   1410\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1411\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_exception_on_not_ok_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mstatus\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D , MaxPool2D , Flatten , Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def Cov_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 2, padding='valid', input_shape=(10, 9), activation=\"selu\"))\n",
    "    model.add(Conv1D(64, 2, padding='valid', activation=\"selu\"))\n",
    "    model.add(Conv1D(128, 2, padding='valid', activation=\"selu\"))\n",
    "    model.add(Conv1D(256, 2, padding='valid', activation=\"selu\"))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    opt = Adam(lr=0.001, clipnorm=1)\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.mean_squared_error,\n",
    "                  metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# fit network\n",
    "cov_model = Cov_model()\n",
    "\n",
    "history = cov_model.fit(call_train_X[10000:15000], call_train_Y[10000:15000],\n",
    "                    epochs=50, batch_size=256,\n",
    "                    validation_data=(call_val_X[100:150], call_val_Y[100:150]),\n",
    "                    verbose=2,\n",
    "                    shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "54092"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(call_train_X[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12076 9 8 0.00286393148233\n",
      "12077 8 8 0.00286393148233\n",
      "12077 9 8 3.59737517164e-05\n",
      "12078 7 8 0.00286393148233\n",
      "12078 8 8 3.59737517164e-05\n",
      "12078 9 8 0.00297874411765\n",
      "12079 6 8 0.00286393148233\n",
      "12079 7 8 3.59737517164e-05\n",
      "12079 8 8 0.00297874411765\n",
      "12079 9 8 0.000318559103993\n",
      "12080 5 8 0.00286393148233\n",
      "12080 6 8 3.59737517164e-05\n",
      "12080 7 8 0.00297874411765\n",
      "12080 8 8 0.000318559103993\n",
      "12081 4 8 0.00286393148233\n",
      "12081 5 8 3.59737517164e-05\n",
      "12081 6 8 0.00297874411765\n",
      "12081 7 8 0.000318559103993\n",
      "12082 3 8 0.00286393148233\n",
      "12082 4 8 3.59737517164e-05\n",
      "12082 5 8 0.00297874411765\n",
      "12082 6 8 0.000318559103993\n",
      "12083 2 8 0.00286393148233\n",
      "12083 3 8 3.59737517164e-05\n",
      "12083 4 8 0.00297874411765\n",
      "12083 5 8 0.000318559103993\n",
      "12084 1 8 0.00286393148233\n",
      "12084 2 8 3.59737517164e-05\n",
      "12084 3 8 0.00297874411765\n",
      "12084 4 8 0.000318559103993\n",
      "12085 0 8 0.00286393148233\n",
      "12085 1 8 3.59737517164e-05\n",
      "12085 2 8 0.00297874411765\n",
      "12085 3 8 0.000318559103993\n",
      "12086 0 8 3.59737517164e-05\n",
      "12086 1 8 0.00297874411765\n",
      "12086 2 8 0.000318559103993\n",
      "12087 0 8 0.00297874411765\n",
      "12087 1 8 0.000318559103993\n",
      "12088 0 8 0.000318559103993\n",
      "12093 9 8 0.00410451302802\n",
      "12094 8 8 0.00410451302802\n",
      "12094 9 8 0.00225836145527\n",
      "12095 7 8 0.00410451302802\n",
      "12095 8 8 0.00225836145527\n",
      "12096 6 8 0.00410451302802\n",
      "12096 7 8 0.00225836145527\n",
      "12096 9 8 0.00184864933953\n",
      "12097 5 8 0.00410451302802\n",
      "12097 6 8 0.00225836145527\n",
      "12097 8 8 0.00184864933953\n",
      "26089 9 8 0.00244463288221\n",
      "26090 8 8 0.00244463288221\n",
      "26090 9 8 0.00411922363615\n",
      "26091 7 8 0.00244463288221\n",
      "26091 8 8 0.00411922363615\n",
      "26091 9 8 0.00630291729092\n",
      "26092 6 8 0.00244463288221\n",
      "26092 7 8 0.00411922363615\n",
      "26092 8 8 0.00630291729092\n",
      "26092 9 8 0.0105671176137\n",
      "26093 5 8 0.00244463288221\n",
      "26093 6 8 0.00411922363615\n",
      "26093 7 8 0.00630291729092\n",
      "26093 8 8 0.0105671176137\n",
      "26093 9 8 0.0112089789661\n",
      "26094 4 8 0.00244463288221\n",
      "26094 5 8 0.00411922363615\n",
      "26094 6 8 0.00630291729092\n",
      "26094 7 8 0.0105671176137\n",
      "26094 8 8 0.0112089789661\n",
      "26094 9 8 0.00858699003753\n",
      "26095 3 8 0.00244463288221\n",
      "26095 4 8 0.00411922363615\n",
      "26095 5 8 0.00630291729092\n",
      "26095 6 8 0.0105671176137\n",
      "26095 7 8 0.0112089789661\n",
      "26095 8 8 0.00858699003753\n",
      "26095 9 8 0.00398529588666\n",
      "26096 2 8 0.00244463288221\n",
      "26096 3 8 0.00411922363615\n",
      "26096 4 8 0.00630291729092\n",
      "26096 5 8 0.0105671176137\n",
      "26096 6 8 0.0112089789661\n",
      "26096 7 8 0.00858699003753\n",
      "26096 8 8 0.00398529588666\n",
      "26097 1 8 0.00244463288221\n",
      "26097 2 8 0.00411922363615\n",
      "26097 3 8 0.00630291729092\n",
      "26097 4 8 0.0105671176137\n",
      "26097 5 8 0.0112089789661\n",
      "26097 6 8 0.00858699003753\n",
      "26097 7 8 0.00398529588666\n",
      "26097 9 8 0.00455974837495\n",
      "26098 0 8 0.00244463288221\n",
      "26098 1 8 0.00411922363615\n",
      "26098 2 8 0.00630291729092\n",
      "26098 3 8 0.0105671176137\n",
      "26098 4 8 0.0112089789661\n",
      "26098 5 8 0.00858699003753\n",
      "26098 6 8 0.00398529588666\n",
      "26098 8 8 0.00455974837495\n",
      "26098 9 8 0.00887373301837\n",
      "26099 0 8 0.00411922363615\n",
      "26099 1 8 0.00630291729092\n",
      "26099 2 8 0.0105671176137\n",
      "26099 3 8 0.0112089789661\n",
      "26099 4 8 0.00858699003753\n",
      "26099 5 8 0.00398529588666\n",
      "26099 7 8 0.00455974837495\n",
      "26099 8 8 0.00887373301837\n",
      "26099 9 8 0.0114674415614\n",
      "26100 0 8 0.00630291729092\n",
      "26100 1 8 0.0105671176137\n",
      "26100 2 8 0.0112089789661\n",
      "26100 3 8 0.00858699003753\n",
      "26100 4 8 0.00398529588666\n",
      "26100 6 8 0.00455974837495\n",
      "26100 7 8 0.00887373301837\n",
      "26100 8 8 0.0114674415614\n",
      "26100 9 8 0.0094961026026\n",
      "26101 0 8 0.0105671176137\n",
      "26101 1 8 0.0112089789661\n",
      "26101 2 8 0.00858699003753\n",
      "26101 3 8 0.00398529588666\n",
      "26101 5 8 0.00455974837495\n",
      "26101 6 8 0.00887373301837\n",
      "26101 7 8 0.0114674415614\n",
      "26101 8 8 0.0094961026026\n",
      "26101 9 8 0.00860402921986\n",
      "26102 0 8 0.0112089789661\n",
      "26102 1 8 0.00858699003753\n",
      "26102 2 8 0.00398529588666\n",
      "26102 4 8 0.00455974837495\n",
      "26102 5 8 0.00887373301837\n",
      "26102 6 8 0.0114674415614\n",
      "26102 7 8 0.0094961026026\n",
      "26102 8 8 0.00860402921986\n",
      "26102 9 8 0.00463112669689\n",
      "26103 0 8 0.00858699003753\n",
      "26103 1 8 0.00398529588666\n",
      "26103 3 8 0.00455974837495\n",
      "26103 4 8 0.00887373301837\n",
      "26103 5 8 0.0114674415614\n",
      "26103 6 8 0.0094961026026\n",
      "26103 7 8 0.00860402921986\n",
      "26103 8 8 0.00463112669689\n",
      "26103 9 8 0.00416382105174\n",
      "26104 0 8 0.00398529588666\n",
      "26104 2 8 0.00455974837495\n",
      "26104 3 8 0.00887373301837\n",
      "26104 4 8 0.0114674415614\n",
      "26104 5 8 0.0094961026026\n",
      "26104 6 8 0.00860402921986\n",
      "26104 7 8 0.00463112669689\n",
      "26104 8 8 0.00416382105174\n",
      "26104 9 8 0.00505357421686\n",
      "26105 1 8 0.00455974837495\n",
      "26105 2 8 0.00887373301837\n",
      "26105 3 8 0.0114674415614\n",
      "26105 4 8 0.0094961026026\n",
      "26105 5 8 0.00860402921986\n",
      "26105 6 8 0.00463112669689\n",
      "26105 7 8 0.00416382105174\n",
      "26105 8 8 0.00505357421686\n",
      "26105 9 8 0.010027647453\n",
      "26106 0 8 0.00455974837495\n",
      "26106 1 8 0.00887373301837\n",
      "26106 2 8 0.0114674415614\n",
      "26106 3 8 0.0094961026026\n",
      "26106 4 8 0.00860402921986\n",
      "26106 5 8 0.00463112669689\n",
      "26106 6 8 0.00416382105174\n",
      "26106 7 8 0.00505357421686\n",
      "26106 8 8 0.010027647453\n",
      "26106 9 8 0.00749296630298\n",
      "26107 0 8 0.00887373301837\n",
      "26107 1 8 0.0114674415614\n",
      "26107 2 8 0.0094961026026\n",
      "26107 3 8 0.00860402921986\n",
      "26107 4 8 0.00463112669689\n",
      "26107 5 8 0.00416382105174\n",
      "26107 6 8 0.00505357421686\n",
      "26107 7 8 0.010027647453\n",
      "26107 8 8 0.00749296630298\n",
      "26107 9 8 0.00698461148705\n",
      "26108 0 8 0.0114674415614\n",
      "26108 1 8 0.0094961026026\n",
      "26108 2 8 0.00860402921986\n",
      "26108 3 8 0.00463112669689\n",
      "26108 4 8 0.00416382105174\n",
      "26108 5 8 0.00505357421686\n",
      "26108 6 8 0.010027647453\n",
      "26108 7 8 0.00749296630298\n",
      "26108 8 8 0.00698461148705\n",
      "26108 9 8 0.00526612688848\n",
      "26109 0 8 0.0094961026026\n",
      "26109 1 8 0.00860402921986\n",
      "26109 2 8 0.00463112669689\n",
      "26109 3 8 0.00416382105174\n",
      "26109 4 8 0.00505357421686\n",
      "26109 5 8 0.010027647453\n",
      "26109 6 8 0.00749296630298\n",
      "26109 7 8 0.00698461148705\n",
      "26109 8 8 0.00526612688848\n",
      "26109 9 8 0.00966071213234\n",
      "26110 0 8 0.00860402921986\n",
      "26110 1 8 0.00463112669689\n",
      "26110 2 8 0.00416382105174\n",
      "26110 3 8 0.00505357421686\n",
      "26110 4 8 0.010027647453\n",
      "26110 5 8 0.00749296630298\n",
      "26110 6 8 0.00698461148705\n",
      "26110 7 8 0.00526612688848\n",
      "26110 8 8 0.00966071213234\n",
      "26110 9 8 0.0109322635728\n",
      "26111 0 8 0.00463112669689\n",
      "26111 1 8 0.00416382105174\n",
      "26111 2 8 0.00505357421686\n",
      "26111 3 8 0.010027647453\n",
      "26111 4 8 0.00749296630298\n",
      "26111 5 8 0.00698461148705\n",
      "26111 6 8 0.00526612688848\n",
      "26111 7 8 0.00966071213234\n",
      "26111 8 8 0.0109322635728\n",
      "26111 9 8 0.00801595809705\n",
      "26112 0 8 0.00416382105174\n",
      "26112 1 8 0.00505357421686\n",
      "26112 2 8 0.010027647453\n",
      "26112 3 8 0.00749296630298\n",
      "26112 4 8 0.00698461148705\n",
      "26112 5 8 0.00526612688848\n",
      "26112 6 8 0.00966071213234\n",
      "26112 7 8 0.0109322635728\n",
      "26112 8 8 0.00801595809705\n",
      "26112 9 8 0.00333193738274\n",
      "26113 0 8 0.00505357421686\n",
      "26113 1 8 0.010027647453\n",
      "26113 2 8 0.00749296630298\n",
      "26113 3 8 0.00698461148705\n",
      "26113 4 8 0.00526612688848\n",
      "26113 5 8 0.00966071213234\n",
      "26113 6 8 0.0109322635728\n",
      "26113 7 8 0.00801595809705\n",
      "26113 8 8 0.00333193738274\n",
      "26113 9 8 0.00212004144553\n",
      "26114 0 8 0.010027647453\n",
      "26114 1 8 0.00749296630298\n",
      "26114 2 8 0.00698461148705\n",
      "26114 3 8 0.00526612688848\n",
      "26114 4 8 0.00966071213234\n",
      "26114 5 8 0.0109322635728\n",
      "26114 6 8 0.00801595809705\n",
      "26114 7 8 0.00333193738274\n",
      "26114 8 8 0.00212004144553\n",
      "26114 9 8 0.00591131100696\n",
      "26115 0 8 0.00749296630298\n",
      "26115 1 8 0.00698461148705\n",
      "26115 2 8 0.00526612688848\n",
      "26115 3 8 0.00966071213234\n",
      "26115 4 8 0.0109322635728\n",
      "26115 5 8 0.00801595809705\n",
      "26115 6 8 0.00333193738274\n",
      "26115 7 8 0.00212004144553\n",
      "26115 8 8 0.00591131100696\n",
      "26115 9 8 0.00467923608703\n",
      "26116 0 8 0.00698461148705\n",
      "26116 1 8 0.00526612688848\n",
      "26116 2 8 0.00966071213234\n",
      "26116 3 8 0.0109322635728\n",
      "26116 4 8 0.00801595809705\n",
      "26116 5 8 0.00333193738274\n",
      "26116 6 8 0.00212004144553\n",
      "26116 7 8 0.00591131100696\n",
      "26116 8 8 0.00467923608703\n",
      "26116 9 8 0.00212724501505\n",
      "26117 0 8 0.00526612688848\n",
      "26117 1 8 0.00966071213234\n",
      "26117 2 8 0.0109322635728\n",
      "26117 3 8 0.00801595809705\n",
      "26117 4 8 0.00333193738274\n",
      "26117 5 8 0.00212004144553\n",
      "26117 6 8 0.00591131100696\n",
      "26117 7 8 0.00467923608703\n",
      "26117 8 8 0.00212724501505\n",
      "26118 0 8 0.00966071213234\n",
      "26118 1 8 0.0109322635728\n",
      "26118 2 8 0.00801595809705\n",
      "26118 3 8 0.00333193738274\n",
      "26118 4 8 0.00212004144553\n",
      "26118 5 8 0.00591131100696\n",
      "26118 6 8 0.00467923608703\n",
      "26118 7 8 0.00212724501505\n",
      "26118 9 8 0.00153714700592\n",
      "26119 0 8 0.0109322635728\n",
      "26119 1 8 0.00801595809705\n",
      "26119 2 8 0.00333193738274\n",
      "26119 3 8 0.00212004144553\n",
      "26119 4 8 0.00591131100696\n",
      "26119 5 8 0.00467923608703\n",
      "26119 6 8 0.00212724501505\n",
      "26119 8 8 0.00153714700592\n",
      "26119 9 8 0.00277143473715\n",
      "26120 0 8 0.00801595809705\n",
      "26120 1 8 0.00333193738274\n",
      "26120 2 8 0.00212004144553\n",
      "26120 3 8 0.00591131100696\n",
      "26120 4 8 0.00467923608703\n",
      "26120 5 8 0.00212724501505\n",
      "26120 7 8 0.00153714700592\n",
      "26120 8 8 0.00277143473715\n",
      "26121 0 8 0.00333193738274\n",
      "26121 1 8 0.00212004144553\n",
      "26121 2 8 0.00591131100696\n",
      "26121 3 8 0.00467923608703\n",
      "26121 4 8 0.00212724501505\n",
      "26121 6 8 0.00153714700592\n",
      "26121 7 8 0.00277143473715\n",
      "26122 0 8 0.00212004144553\n",
      "26122 1 8 0.00591131100696\n",
      "26122 2 8 0.00467923608703\n",
      "26122 3 8 0.00212724501505\n",
      "26122 5 8 0.00153714700592\n",
      "26122 6 8 0.00277143473715\n",
      "26123 0 8 0.00591131100696\n",
      "26123 1 8 0.00467923608703\n",
      "26123 2 8 0.00212724501505\n",
      "26123 4 8 0.00153714700592\n",
      "26123 5 8 0.00277143473715\n",
      "26124 0 8 0.00467923608703\n",
      "26124 1 8 0.00212724501505\n",
      "26124 3 8 0.00153714700592\n",
      "26124 4 8 0.00277143473715\n",
      "26125 0 8 0.00212724501505\n",
      "26125 2 8 0.00153714700592\n",
      "26125 3 8 0.00277143473715\n",
      "26126 1 8 0.00153714700592\n",
      "26126 2 8 0.00277143473715\n",
      "26127 0 8 0.00153714700592\n",
      "26127 1 8 0.00277143473715\n",
      "26128 0 8 0.00277143473715\n",
      "26866 7 8 0.00398282919254\n",
      "26866 8 8 0.0047279897165\n",
      "26866 9 8 0.00103865693671\n",
      "26867 6 8 0.00398282919254\n",
      "26867 7 8 0.0047279897165\n",
      "26867 8 8 0.00103865693671\n",
      "26867 9 8 0.00555057445115\n",
      "26868 5 8 0.00398282919254\n",
      "26868 6 8 0.0047279897165\n",
      "26868 7 8 0.00103865693671\n",
      "26868 8 8 0.00555057445115\n",
      "26868 9 8 0.00880277866473\n",
      "26869 4 8 0.00398282919254\n",
      "26869 5 8 0.0047279897165\n",
      "26869 6 8 0.00103865693671\n",
      "26869 7 8 0.00555057445115\n",
      "26869 8 8 0.00880277866473\n",
      "26869 9 8 0.00617870925902\n",
      "26870 3 8 0.00398282919254\n",
      "26870 4 8 0.0047279897165\n",
      "26870 5 8 0.00103865693671\n",
      "26870 6 8 0.00555057445115\n",
      "26870 7 8 0.00880277866473\n",
      "26870 8 8 0.00617870925902\n",
      "26870 9 8 0.00717230586553\n",
      "26871 2 8 0.00398282919254\n",
      "26871 3 8 0.0047279897165\n",
      "26871 4 8 0.00103865693671\n",
      "26871 5 8 0.00555057445115\n",
      "26871 6 8 0.00880277866473\n",
      "26871 7 8 0.00617870925902\n",
      "26871 8 8 0.00717230586553\n",
      "26871 9 8 0.0112993984634\n",
      "26872 1 8 0.00398282919254\n",
      "26872 2 8 0.0047279897165\n",
      "26872 3 8 0.00103865693671\n",
      "26872 4 8 0.00555057445115\n",
      "26872 5 8 0.00880277866473\n",
      "26872 6 8 0.00617870925902\n",
      "26872 7 8 0.00717230586553\n",
      "26872 8 8 0.0112993984634\n",
      "26872 9 8 0.0145154916113\n",
      "26873 0 8 0.00398282919254\n",
      "26873 1 8 0.0047279897165\n",
      "26873 2 8 0.00103865693671\n",
      "26873 3 8 0.00555057445115\n",
      "26873 4 8 0.00880277866473\n",
      "26873 5 8 0.00617870925902\n",
      "26873 6 8 0.00717230586553\n",
      "26873 7 8 0.0112993984634\n",
      "26873 8 8 0.0145154916113\n",
      "26873 9 8 0.0111374406934\n",
      "26874 0 8 0.0047279897165\n",
      "26874 1 8 0.00103865693671\n",
      "26874 2 8 0.00555057445115\n",
      "26874 3 8 0.00880277866473\n",
      "26874 4 8 0.00617870925902\n",
      "26874 5 8 0.00717230586553\n",
      "26874 6 8 0.0112993984634\n",
      "26874 7 8 0.0145154916113\n",
      "26874 8 8 0.0111374406934\n",
      "26874 9 8 0.0103711571614\n",
      "26875 0 8 0.00103865693671\n",
      "26875 1 8 0.00555057445115\n",
      "26875 2 8 0.00880277866473\n",
      "26875 3 8 0.00617870925902\n",
      "26875 4 8 0.00717230586553\n",
      "26875 5 8 0.0112993984634\n",
      "26875 6 8 0.0145154916113\n",
      "26875 7 8 0.0111374406934\n",
      "26875 8 8 0.0103711571614\n",
      "26875 9 8 0.00883079140899\n",
      "26876 0 8 0.00555057445115\n",
      "26876 1 8 0.00880277866473\n",
      "26876 2 8 0.00617870925902\n",
      "26876 3 8 0.00717230586553\n",
      "26876 4 8 0.0112993984634\n",
      "26876 5 8 0.0145154916113\n",
      "26876 6 8 0.0111374406934\n",
      "26876 7 8 0.0103711571614\n",
      "26876 8 8 0.00883079140899\n",
      "26876 9 8 0.0121937730318\n",
      "26877 0 8 0.00880277866473\n",
      "26877 1 8 0.00617870925902\n",
      "26877 2 8 0.00717230586553\n",
      "26877 3 8 0.0112993984634\n",
      "26877 4 8 0.0145154916113\n",
      "26877 5 8 0.0111374406934\n",
      "26877 6 8 0.0103711571614\n",
      "26877 7 8 0.00883079140899\n",
      "26877 8 8 0.0121937730318\n",
      "26877 9 8 0.0134243808125\n",
      "26878 0 8 0.00617870925902\n",
      "26878 1 8 0.00717230586553\n",
      "26878 2 8 0.0112993984634\n",
      "26878 3 8 0.0145154916113\n",
      "26878 4 8 0.0111374406934\n",
      "26878 5 8 0.0103711571614\n",
      "26878 6 8 0.00883079140899\n",
      "26878 7 8 0.0121937730318\n",
      "26878 8 8 0.0134243808125\n",
      "26878 9 8 0.0104119976067\n",
      "26879 0 8 0.00717230586553\n",
      "26879 1 8 0.0112993984634\n",
      "26879 2 8 0.0145154916113\n",
      "26879 3 8 0.0111374406934\n",
      "26879 4 8 0.0103711571614\n",
      "26879 5 8 0.00883079140899\n",
      "26879 6 8 0.0121937730318\n",
      "26879 7 8 0.0134243808125\n",
      "26879 8 8 0.0104119976067\n",
      "26879 9 8 0.00777994255329\n",
      "26880 0 8 0.0112993984634\n",
      "26880 1 8 0.0145154916113\n",
      "26880 2 8 0.0111374406934\n",
      "26880 3 8 0.0103711571614\n",
      "26880 4 8 0.00883079140899\n",
      "26880 5 8 0.0121937730318\n",
      "26880 6 8 0.0134243808125\n",
      "26880 7 8 0.0104119976067\n",
      "26880 8 8 0.00777994255329\n",
      "26880 9 8 0.0107474091323\n",
      "26881 0 8 0.0145154916113\n",
      "26881 1 8 0.0111374406934\n",
      "26881 2 8 0.0103711571614\n",
      "26881 3 8 0.00883079140899\n",
      "26881 4 8 0.0121937730318\n",
      "26881 5 8 0.0134243808125\n",
      "26881 6 8 0.0104119976067\n",
      "26881 7 8 0.00777994255329\n",
      "26881 8 8 0.0107474091323\n",
      "26881 9 8 0.00787134876925\n",
      "26882 0 8 0.0111374406934\n",
      "26882 1 8 0.0103711571614\n",
      "26882 2 8 0.00883079140899\n",
      "26882 3 8 0.0121937730318\n",
      "26882 4 8 0.0134243808125\n",
      "26882 5 8 0.0104119976067\n",
      "26882 6 8 0.00777994255329\n",
      "26882 7 8 0.0107474091323\n",
      "26882 8 8 0.00787134876925\n",
      "26882 9 8 0.00544562902741\n",
      "26883 0 8 0.0103711571614\n",
      "26883 1 8 0.00883079140899\n",
      "26883 2 8 0.0121937730318\n",
      "26883 3 8 0.0134243808125\n",
      "26883 4 8 0.0104119976067\n",
      "26883 5 8 0.00777994255329\n",
      "26883 6 8 0.0107474091323\n",
      "26883 7 8 0.00787134876925\n",
      "26883 8 8 0.00544562902741\n",
      "26883 9 8 0.00244043765668\n",
      "26884 0 8 0.00883079140899\n",
      "26884 1 8 0.0121937730318\n",
      "26884 2 8 0.0134243808125\n",
      "26884 3 8 0.0104119976067\n",
      "26884 4 8 0.00777994255329\n",
      "26884 5 8 0.0107474091323\n",
      "26884 6 8 0.00787134876925\n",
      "26884 7 8 0.00544562902741\n",
      "26884 8 8 0.00244043765668\n",
      "26884 9 8 0.00689330194536\n",
      "26885 0 8 0.0121937730318\n",
      "26885 1 8 0.0134243808125\n",
      "26885 2 8 0.0104119976067\n",
      "26885 3 8 0.00777994255329\n",
      "26885 4 8 0.0107474091323\n",
      "26885 5 8 0.00787134876925\n",
      "26885 6 8 0.00544562902741\n",
      "26885 7 8 0.00244043765668\n",
      "26885 8 8 0.00689330194536\n",
      "26885 9 8 0.00213034560454\n",
      "26886 0 8 0.0134243808125\n",
      "26886 1 8 0.0104119976067\n",
      "26886 2 8 0.00777994255329\n",
      "26886 3 8 0.0107474091323\n",
      "26886 4 8 0.00787134876925\n",
      "26886 5 8 0.00544562902741\n",
      "26886 6 8 0.00244043765668\n",
      "26886 7 8 0.00689330194536\n",
      "26886 8 8 0.00213034560454\n",
      "26886 9 8 0.00248525604712\n",
      "26887 0 8 0.0104119976067\n",
      "26887 1 8 0.00777994255329\n",
      "26887 2 8 0.0107474091323\n",
      "26887 3 8 0.00787134876925\n",
      "26887 4 8 0.00544562902741\n",
      "26887 5 8 0.00244043765668\n",
      "26887 6 8 0.00689330194536\n",
      "26887 7 8 0.00213034560454\n",
      "26887 8 8 0.00248525604712\n",
      "26887 9 8 0.00688178699521\n",
      "26888 0 8 0.00777994255329\n",
      "26888 1 8 0.0107474091323\n",
      "26888 2 8 0.00787134876925\n",
      "26888 3 8 0.00544562902741\n",
      "26888 4 8 0.00244043765668\n",
      "26888 5 8 0.00689330194536\n",
      "26888 6 8 0.00213034560454\n",
      "26888 7 8 0.00248525604712\n",
      "26888 8 8 0.00688178699521\n",
      "26888 9 8 0.00993469635686\n",
      "26889 0 8 0.0107474091323\n",
      "26889 1 8 0.00787134876925\n",
      "26889 2 8 0.00544562902741\n",
      "26889 3 8 0.00244043765668\n",
      "26889 4 8 0.00689330194536\n",
      "26889 5 8 0.00213034560454\n",
      "26889 6 8 0.00248525604712\n",
      "26889 7 8 0.00688178699521\n",
      "26889 8 8 0.00993469635686\n",
      "26889 9 8 0.00797259210032\n",
      "26890 0 8 0.00787134876925\n",
      "26890 1 8 0.00544562902741\n",
      "26890 2 8 0.00244043765668\n",
      "26890 3 8 0.00689330194536\n",
      "26890 4 8 0.00213034560454\n",
      "26890 5 8 0.00248525604712\n",
      "26890 6 8 0.00688178699521\n",
      "26890 7 8 0.00993469635686\n",
      "26890 8 8 0.00797259210032\n",
      "26890 9 8 0.00455382740894\n",
      "26891 0 8 0.00544562902741\n",
      "26891 1 8 0.00244043765668\n",
      "26891 2 8 0.00689330194536\n",
      "26891 3 8 0.00213034560454\n",
      "26891 4 8 0.00248525604712\n",
      "26891 5 8 0.00688178699521\n",
      "26891 6 8 0.00993469635686\n",
      "26891 7 8 0.00797259210032\n",
      "26891 8 8 0.00455382740894\n",
      "26891 9 8 0.00316964653809\n",
      "26892 0 8 0.00244043765668\n",
      "26892 1 8 0.00689330194536\n",
      "26892 2 8 0.00213034560454\n",
      "26892 3 8 0.00248525604712\n",
      "26892 4 8 0.00688178699521\n",
      "26892 5 8 0.00993469635686\n",
      "26892 6 8 0.00797259210032\n",
      "26892 7 8 0.00455382740894\n",
      "26892 8 8 0.00316964653809\n",
      "26893 0 8 0.00689330194536\n",
      "26893 1 8 0.00213034560454\n",
      "26893 2 8 0.00248525604712\n",
      "26893 3 8 0.00688178699521\n",
      "26893 4 8 0.00993469635686\n",
      "26893 5 8 0.00797259210032\n",
      "26893 6 8 0.00455382740894\n",
      "26893 7 8 0.00316964653809\n",
      "26893 9 8 0.000763863553893\n",
      "26894 0 8 0.00213034560454\n",
      "26894 1 8 0.00248525604712\n",
      "26894 2 8 0.00688178699521\n",
      "26894 3 8 0.00993469635686\n",
      "26894 4 8 0.00797259210032\n",
      "26894 5 8 0.00455382740894\n",
      "26894 6 8 0.00316964653809\n",
      "26894 8 8 0.000763863553893\n",
      "26895 0 8 0.00248525604712\n",
      "26895 1 8 0.00688178699521\n",
      "26895 2 8 0.00993469635686\n",
      "26895 3 8 0.00797259210032\n",
      "26895 4 8 0.00455382740894\n",
      "26895 5 8 0.00316964653809\n",
      "26895 7 8 0.000763863553893\n",
      "26895 9 8 0.000854128562688\n",
      "26896 0 8 0.00688178699521\n",
      "26896 1 8 0.00993469635686\n",
      "26896 2 8 0.00797259210032\n",
      "26896 3 8 0.00455382740894\n",
      "26896 4 8 0.00316964653809\n",
      "26896 6 8 0.000763863553893\n",
      "26896 8 8 0.000854128562688\n",
      "26897 0 8 0.00993469635686\n",
      "26897 1 8 0.00797259210032\n",
      "26897 2 8 0.00455382740894\n",
      "26897 3 8 0.00316964653809\n",
      "26897 5 8 0.000763863553893\n",
      "26897 7 8 0.000854128562688\n",
      "26898 0 8 0.00797259210032\n",
      "26898 1 8 0.00455382740894\n",
      "26898 2 8 0.00316964653809\n",
      "26898 4 8 0.000763863553893\n",
      "26898 6 8 0.000854128562688\n",
      "26899 0 8 0.00455382740894\n",
      "26899 1 8 0.00316964653809\n",
      "26899 3 8 0.000763863553893\n",
      "26899 5 8 0.000854128562688\n",
      "26900 0 8 0.00316964653809\n",
      "26900 2 8 0.000763863553893\n",
      "26900 4 8 0.000854128562688\n",
      "26901 1 8 0.000763863553893\n",
      "26901 3 8 0.000854128562688\n",
      "26901 9 8 0.00154406223365\n",
      "26902 0 8 0.000763863553893\n",
      "26902 2 8 0.000854128562688\n",
      "26902 8 8 0.00154406223365\n",
      "26902 9 8 0.00540567413126\n",
      "26903 1 8 0.000854128562688\n",
      "26903 7 8 0.00154406223365\n",
      "26903 8 8 0.00540567413126\n",
      "26903 9 8 0.00250060163422\n",
      "26904 0 8 0.000854128562688\n",
      "26904 6 8 0.00154406223365\n",
      "26904 7 8 0.00540567413126\n",
      "26904 8 8 0.00250060163422\n",
      "26904 9 8 0.0069604972654\n",
      "26905 5 8 0.00154406223365\n",
      "26905 6 8 0.00540567413126\n",
      "26905 7 8 0.00250060163422\n",
      "26905 8 8 0.0069604972654\n",
      "26905 9 8 0.0111760863048\n",
      "26906 4 8 0.00154406223365\n",
      "26906 5 8 0.00540567413126\n",
      "26906 6 8 0.00250060163422\n",
      "26906 7 8 0.0069604972654\n",
      "26906 8 8 0.0111760863048\n",
      "26906 9 8 0.0145891049325\n",
      "26907 3 8 0.00154406223365\n",
      "26907 4 8 0.00540567413126\n",
      "26907 5 8 0.00250060163422\n",
      "26907 6 8 0.0069604972654\n",
      "26907 7 8 0.0111760863048\n",
      "26907 8 8 0.0145891049325\n",
      "26907 9 8 0.0168730505246\n",
      "26908 2 8 0.00154406223365\n",
      "26908 3 8 0.00540567413126\n",
      "26908 4 8 0.00250060163422\n",
      "26908 5 8 0.0069604972654\n",
      "26908 6 8 0.0111760863048\n",
      "26908 7 8 0.0145891049325\n",
      "26908 8 8 0.0168730505246\n",
      "26908 9 8 0.0194909370854\n",
      "26909 1 8 0.00154406223365\n",
      "26909 2 8 0.00540567413126\n",
      "26909 3 8 0.00250060163422\n",
      "26909 4 8 0.0069604972654\n",
      "26909 5 8 0.0111760863048\n",
      "26909 6 8 0.0145891049325\n",
      "26909 7 8 0.0168730505246\n",
      "26909 8 8 0.0194909370854\n",
      "26909 9 8 0.0198308073139\n",
      "26910 0 8 0.00154406223365\n",
      "26910 1 8 0.00540567413126\n",
      "26910 2 8 0.00250060163422\n",
      "26910 3 8 0.0069604972654\n",
      "26910 4 8 0.0111760863048\n",
      "26910 5 8 0.0145891049325\n",
      "26910 6 8 0.0168730505246\n",
      "26910 7 8 0.0194909370854\n",
      "26910 8 8 0.0198308073139\n",
      "26910 9 8 0.0184984443488\n",
      "26911 0 8 0.00540567413126\n",
      "26911 1 8 0.00250060163422\n",
      "26911 2 8 0.0069604972654\n",
      "26911 3 8 0.0111760863048\n",
      "26911 4 8 0.0145891049325\n",
      "26911 5 8 0.0168730505246\n",
      "26911 6 8 0.0194909370854\n",
      "26911 7 8 0.0198308073139\n",
      "26911 8 8 0.0184984443488\n",
      "26911 9 8 0.0171096736144\n",
      "26912 0 8 0.00250060163422\n",
      "26912 1 8 0.0069604972654\n",
      "26912 2 8 0.0111760863048\n",
      "26912 3 8 0.0145891049325\n",
      "26912 4 8 0.0168730505246\n",
      "26912 5 8 0.0194909370854\n",
      "26912 6 8 0.0198308073139\n",
      "26912 7 8 0.0184984443488\n",
      "26912 8 8 0.0171096736144\n",
      "26913 0 8 0.0069604972654\n",
      "26913 1 8 0.0111760863048\n",
      "26913 2 8 0.0145891049325\n",
      "26913 3 8 0.0168730505246\n",
      "26913 4 8 0.0194909370854\n",
      "26913 5 8 0.0198308073139\n",
      "26913 6 8 0.0184984443488\n",
      "26913 7 8 0.0171096736144\n",
      "26914 0 8 0.0111760863048\n",
      "26914 1 8 0.0145891049325\n",
      "26914 2 8 0.0168730505246\n",
      "26914 3 8 0.0194909370854\n",
      "26914 4 8 0.0198308073139\n",
      "26914 5 8 0.0184984443488\n",
      "26914 6 8 0.0171096736144\n",
      "26915 0 8 0.0145891049325\n",
      "26915 1 8 0.0168730505246\n",
      "26915 2 8 0.0194909370854\n",
      "26915 3 8 0.0198308073139\n",
      "26915 4 8 0.0184984443488\n",
      "26915 5 8 0.0171096736144\n",
      "26916 0 8 0.0168730505246\n",
      "26916 1 8 0.0194909370854\n",
      "26916 2 8 0.0198308073139\n",
      "26916 3 8 0.0184984443488\n",
      "26916 4 8 0.0171096736144\n",
      "26917 0 8 0.0194909370854\n",
      "26917 1 8 0.0198308073139\n",
      "26917 2 8 0.0184984443488\n",
      "26917 3 8 0.0171096736144\n",
      "26918 0 8 0.0198308073139\n",
      "26918 1 8 0.0184984443488\n",
      "26918 2 8 0.0171096736144\n",
      "26919 0 8 0.0184984443488\n",
      "26919 1 8 0.0171096736144\n",
      "26920 0 8 0.0171096736144\n",
      "67122 9 8 0.000728140990011\n",
      "67123 8 8 0.000728140990011\n",
      "67123 9 8 0.000474431754403\n",
      "67124 7 8 0.000728140990011\n",
      "67124 8 8 0.000474431754403\n",
      "67125 6 8 0.000728140990011\n",
      "67125 7 8 0.000474431754403\n",
      "67126 5 8 0.000728140990011\n",
      "67126 6 8 0.000474431754403\n",
      "67127 4 8 0.000728140990011\n",
      "67127 5 8 0.000474431754403\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''画图'''\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import Line\n",
    "\n",
    "output_folder = r'.\\data\\out'\n",
    "csv_list = os.listdir(output_folder)\n",
    "\n",
    "for datafile in csv_list:\n",
    "    csv_path = output_folder +\"\\\\\"+ datafile\n",
    "    data = pd.read_csv(csv_path, encoding = 'utf-8', index_col= False)\n",
    "    data = data['iv']\n",
    "    x = list(range(1,len(data)+1))\n",
    "    #print('x',x)\n",
    "    #print('data', data)\n",
    "    plt.plot(x, data, 'ro-', color='#4169E1', alpha=0.8, linewidth=1, label='iv折线图')\n",
    "    plt.savefig('./data/out_pic/'+ datafile + '.jpg')\n",
    "    plt.clf()\n",
    "    line = (\n",
    "        Line()\n",
    "        .set_global_opts(\n",
    "            tooltip_opts=opts.TooltipOpts(is_show=False),\n",
    "            xaxis_opts=opts.AxisOpts(type_=\"value\"),\n",
    "            yaxis_opts=opts.AxisOpts(\n",
    "                type_=\"value\",\n",
    "                axistick_opts=opts.AxisTickOpts(is_show=True),\n",
    "                splitline_opts=opts.SplitLineOpts(is_show=True),\n",
    "            ),\n",
    "        )\n",
    "        .add_xaxis(xaxis_data=x)\n",
    "        .add_yaxis(\n",
    "            series_name=\"基本折线图\",\n",
    "            y_axis=data,\n",
    "            symbol=\"emptyCircle\",\n",
    "            is_symbol_show=True,\n",
    "            label_opts=opts.LabelOpts(is_show=False),\n",
    "        )\n",
    "    )\n",
    "    line.render('./data/out_pic/'+ datafile + '.html')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D, Flatten\n",
    "\n",
    "\n",
    "# design network\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 2, padding='valid', input_shape=(10,10), activation=\"relu\"))\n",
    "    model.add(Conv1D(62, 2, padding='valid', activation=\"relu\"))\n",
    "    model.add(Conv1D(128, 2, padding='valid', activation=\"relu\"))\n",
    "    model.add(Conv1D(256, 2, padding='valid', activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    # plot history\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    # plot history\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    return model1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}