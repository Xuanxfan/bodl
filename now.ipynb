{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def bs_price(S,K,sigma,r,T, year_rate = 252, option_type = \"call\"):\n",
    "    '''\n",
    "    bs 期权定价 输出为期权价格\n",
    "    输入格式：\n",
    "    S:标的价格\n",
    "    K:行权价\n",
    "    sigma:波动率\n",
    "    r:无风险利率\n",
    "    T:年华剩余期限\n",
    "    year_rate:年化系数\n",
    "    '''\n",
    "\n",
    "    T = T/year_rate\n",
    "    d1 = (np.log(S/K) + (r + pow(sigma,2)/2)*T) / (sigma*np.sqrt(T))\n",
    "    d2 = d1 - sigma*np.sqrt(T)\n",
    "    if option_type == 'call':\n",
    "        # return S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)\n",
    "        return np.maximum(S - K, 0) if T==0 else S*norm.cdf(d1) - K*np.exp(-r*T)*norm.cdf(d2)\n",
    "    else :\n",
    "        # return K*np.exp(-r*T)*norm.cdf(-d2) - S*norm.cdf(-d1)\n",
    "        return np.maximum(K-S,0) if T==0 else K*np.exp(-r*T)*norm.cdf(-1*d2) - S*norm.cdf(-1*d1)\n",
    "\n",
    "def bs_vega(S,K,sigma,r,T ,year_rate = 252):\n",
    "    '''\n",
    "    计算vega\n",
    "    '''\n",
    "    T = T/year_rate\n",
    "    d1 = (np.log(S/K) + (r + pow(sigma,2)/2)*T) / (sigma*np.sqrt(np.abs(T)) )\n",
    "    return S*norm.pdf(d1)*np.sqrt(np.abs(T))\n",
    "    # return S * np.sqrt(abs(T)) * np.exp(-pow(d1,2)/2) / np.sqrt(2*np.pi)\n",
    "\n",
    "def iv_bs_bisection(S, K, r, T, price, option_type, iv_uplimit = 0.985, iv_downlimit = 0.015, precision = 3, year_rate = 365, max_iterations = 400):\n",
    "    '''二分法求iv'''\n",
    "    left_iv, right_iv = iv_downlimit, iv_uplimit\n",
    "    # left_price = BS_price(S,K,left_iv, r, T,  year_rate = year_rate, option_type = option_type)\n",
    "    # right_price= BS_price(S,K,right_iv, r, T,  year_rate = year_rate, option_type = option_type)\n",
    "    mid_iv = (left_iv + right_iv)/2\n",
    "    mid_price = bs_price(S,K,mid_iv, r, T,  year_rate = year_rate, option_type = option_type)\n",
    "    # print(f\"first, the mid price is {mid_price}, the price is {price}\")\n",
    "    cnt = 0\n",
    "    while abs(price - mid_price) >= 0.1**precision and cnt < max_iterations:\n",
    "        if mid_price < price :\n",
    "            left_iv = mid_iv\n",
    "        else:\n",
    "            right_iv = mid_iv\n",
    "        mid_iv = (left_iv + right_iv)/2\n",
    "        # if mid_iv < iv_uplimit or mid_iv > iv_downlimit:\n",
    "        #     break\n",
    "        # print(f\"cnt = {cnt}, the left is{left_iv}, the right is{right_iv}, the mid is {mid_iv}\")\n",
    "        cnt += 1\n",
    "        mid_price = bs_price(S, K, mid_iv, r, T,  year_rate = year_rate, option_type = option_type)\n",
    "    return mid_iv\n",
    "\n",
    "def find_vol_newton( S, K, r, T, target_value, option_type, start_sigma = 0.5, precision = 3, year_rate = 252, max_iterations = 200):\n",
    "    '''迭代法求iv'''\n",
    "    sigma = start_sigma\n",
    "    for i in range(0, max_iterations):\n",
    "        bs_price_ = bs_price(S,K,sigma,r,T, year_rate = year_rate, option_type = option_type)\n",
    "        vega = bs_vega(S, K, T, r, sigma, year_rate = year_rate)*100\n",
    "        diff = target_value - bs_price_  # our root\n",
    "        if (abs(diff) < 0.1**precision):\n",
    "            return sigma\n",
    "        sigma = sigma + diff/(vega) # f(x) / f'(x)\n",
    "    return sigma # value wasn't found, return best guess so far\n",
    "\n",
    "def change(type_name):\n",
    "    if type_name == '认购':\n",
    "        return \"call\"\n",
    "    elif type_name == '认沽':\n",
    "        return \"put\"\n",
    "    else:\n",
    "        return \"wrong_type\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000001.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "f:\\annacoda\\envs\\tensorflow\\lib\\site-packages\\ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000002.csv\n",
      "10000003.csv\n",
      "10000004.csv\n",
      "10000005.csv\n",
      "10000006.csv\n",
      "10000007.csv\n",
      "10000008.csv\n",
      "10000009.csv\n",
      "10000010.csv\n",
      "10000011.csv\n",
      "10000012.csv\n",
      "10000013.csv\n",
      "10000014.csv\n",
      "10000015.csv\n",
      "10000016.csv\n",
      "10000017.csv\n",
      "10000018.csv\n",
      "10000019.csv\n",
      "10000020.csv\n",
      "10000021.csv\n",
      "10000022.csv\n",
      "10000023.csv\n",
      "10000024.csv\n",
      "10000025.csv\n",
      "10000026.csv\n",
      "10000027.csv\n",
      "10000028.csv\n",
      "10000029.csv\n",
      "10000030.csv\n",
      "10000031.csv\n",
      "10000032.csv\n",
      "10000033.csv\n",
      "10000034.csv\n",
      "10000035.csv\n",
      "10000036.csv\n",
      "10000037.csv\n",
      "10000038.csv\n",
      "10000039.csv\n",
      "10000040.csv\n",
      "10000041.csv\n",
      "10000042.csv\n",
      "10000043.csv\n",
      "10000044.csv\n",
      "10000045.csv\n",
      "10000046.csv\n",
      "10000047.csv\n",
      "10000048.csv\n",
      "10000049.csv\n",
      "10000050.csv\n",
      "10000051.csv\n",
      "10000052.csv\n",
      "10000053.csv\n",
      "10000054.csv\n",
      "10000055.csv\n",
      "10000056.csv\n",
      "10000057.csv\n",
      "10000058.csv\n",
      "10000059.csv\n",
      "10000060.csv\n",
      "10000061.csv\n",
      "10000062.csv\n",
      "10000063.csv\n",
      "10000064.csv\n",
      "10000065.csv\n",
      "10000066.csv\n",
      "10000067.csv\n",
      "10000068.csv\n",
      "10000069.csv\n",
      "10000070.csv\n",
      "10000071.csv\n",
      "10000072.csv\n",
      "10000073.csv\n",
      "10000074.csv\n",
      "10000075.csv\n",
      "10000076.csv\n",
      "10000077.csv\n",
      "10000078.csv\n",
      "10000079.csv\n",
      "10000080.csv\n",
      "10000081.csv\n",
      "10000082.csv\n",
      "10000083.csv\n",
      "10000084.csv\n",
      "10000085.csv\n",
      "10000086.csv\n",
      "10000087.csv\n",
      "10000088.csv\n",
      "10000089.csv\n",
      "10000090.csv\n",
      "10000091.csv\n",
      "10000092.csv\n",
      "10000093.csv\n",
      "10000094.csv\n",
      "10000095.csv\n",
      "10000096.csv\n",
      "10000097.csv\n",
      "10000098.csv\n",
      "10000099.csv\n",
      "10000100.csv\n",
      "10000101.csv\n",
      "10000102.csv\n",
      "10000103.csv\n",
      "10000104.csv\n",
      "10000105.csv\n",
      "10000106.csv\n",
      "10000107.csv\n",
      "10000108.csv\n",
      "10000109.csv\n",
      "10000110.csv\n",
      "10000111.csv\n",
      "10000112.csv\n",
      "10000113.csv\n",
      "10000114.csv\n",
      "10000115.csv\n",
      "10000116.csv\n",
      "10000117.csv\n",
      "10000118.csv\n",
      "10000119.csv\n",
      "10000120.csv\n",
      "10000121.csv\n",
      "10000122.csv\n",
      "10000123.csv\n",
      "10000124.csv\n",
      "10000125.csv\n",
      "10000126.csv\n",
      "10000127.csv\n",
      "10000128.csv\n",
      "10000129.csv\n",
      "10000130.csv\n",
      "10000131.csv\n",
      "10000132.csv\n",
      "10000133.csv\n",
      "10000134.csv\n",
      "10000135.csv\n",
      "10000136.csv\n",
      "10000137.csv\n",
      "10000138.csv\n",
      "10000139.csv\n",
      "10000140.csv\n",
      "10000141.csv\n",
      "10000142.csv\n",
      "10000143.csv\n",
      "10000144.csv\n",
      "10000145.csv\n",
      "10000146.csv\n",
      "10000147.csv\n",
      "10000148.csv\n",
      "10000149.csv\n",
      "10000150.csv\n",
      "10000151.csv\n",
      "10000152.csv\n",
      "10000153.csv\n",
      "10000154.csv\n",
      "10000155.csv\n",
      "10000156.csv\n",
      "10000157.csv\n",
      "10000158.csv\n",
      "10000159.csv\n",
      "10000160.csv\n",
      "10000161.csv\n",
      "10000162.csv\n",
      "10000163.csv\n",
      "10000164.csv\n",
      "10000165.csv\n",
      "10000166.csv\n",
      "10000167.csv\n",
      "10000168.csv\n",
      "10000169.csv\n",
      "10000170.csv\n",
      "10000171.csv\n",
      "10000172.csv\n",
      "10000173.csv\n",
      "10000174.csv\n",
      "10000175.csv\n",
      "10000176.csv\n",
      "10000177.csv\n",
      "10000178.csv\n",
      "10000179.csv\n",
      "10000180.csv\n",
      "10000181.csv\n",
      "10000182.csv\n",
      "10000183.csv\n",
      "10000184.csv\n",
      "10000185.csv\n",
      "10000186.csv\n",
      "10000187.csv\n",
      "10000188.csv\n",
      "10000189.csv\n",
      "10000190.csv\n",
      "10000191.csv\n",
      "10000192.csv\n",
      "10000193.csv\n",
      "10000194.csv\n",
      "10000195.csv\n",
      "10000196.csv\n",
      "10000197.csv\n",
      "10000198.csv\n",
      "10000199.csv\n",
      "10000200.csv\n",
      "10000201.csv\n",
      "10000202.csv\n",
      "10000203.csv\n",
      "10000204.csv\n",
      "10000205.csv\n",
      "10000206.csv\n",
      "10000207.csv\n",
      "10000208.csv\n",
      "10000209.csv\n",
      "10000210.csv\n",
      "10000211.csv\n",
      "10000212.csv\n",
      "10000213.csv\n",
      "10000214.csv\n",
      "10000215.csv\n",
      "10000216.csv\n",
      "10000217.csv\n",
      "10000218.csv\n",
      "10000219.csv\n",
      "10000220.csv\n",
      "10000221.csv\n",
      "10000222.csv\n",
      "10000223.csv\n",
      "10000224.csv\n",
      "10000225.csv\n",
      "10000226.csv\n",
      "10000227.csv\n",
      "10000228.csv\n",
      "10000229.csv\n",
      "10000230.csv\n",
      "10000231.csv\n",
      "10000232.csv\n",
      "10000233.csv\n",
      "10000234.csv\n",
      "10000235.csv\n",
      "10000236.csv\n",
      "10000237.csv\n",
      "10000238.csv\n",
      "10000239.csv\n",
      "10000240.csv\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-7-24f823ce93c6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     37\u001B[0m     \u001B[1;32mfor\u001B[0m \u001B[0mi\u001B[0m \u001B[1;32min\u001B[0m \u001B[0mrange\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmerged_option2\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     38\u001B[0m         \u001B[0mmerged_option2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'close'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfloat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmerged_option2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'close'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 39\u001B[1;33m         \u001B[0mtmp\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0miv_bs_bisection\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmerged_option2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m's'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmerged_option2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'k'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmerged_option2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'rate'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmerged_option2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'ptmtradeday'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmerged_option2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'close'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0marray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmerged_option2\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m'call_or_put'\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     40\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mabs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtmp\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m0.985\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m0.005\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mabs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtmp\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m0.015\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m0.005\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mabs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtmp\u001B[0m \u001B[1;33m-\u001B[0m \u001B[1;36m0.5\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m<\u001B[0m \u001B[1;36m0.005\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     41\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mi\u001B[0m \u001B[1;33m==\u001B[0m \u001B[1;36m0\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-6-a6b066d5bca3>\u001B[0m in \u001B[0;36miv_bs_bisection\u001B[1;34m(S, K, r, T, price, option_type, iv_uplimit, iv_downlimit, precision, year_rate, max_iterations)\u001B[0m\n\u001B[0;32m     51\u001B[0m         \u001B[1;31m# print(f\"cnt = {cnt}, the left is{left_iv}, the right is{right_iv}, the mid is {mid_iv}\")\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     52\u001B[0m         \u001B[0mcnt\u001B[0m \u001B[1;33m+=\u001B[0m \u001B[1;36m1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 53\u001B[1;33m         \u001B[0mmid_price\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbs_price\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mS\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mK\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmid_iv\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m,\u001B[0m  \u001B[0myear_rate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0myear_rate\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moption_type\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0moption_type\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     54\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmid_iv\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     55\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-6-a6b066d5bca3>\u001B[0m in \u001B[0;36mbs_price\u001B[1;34m(S, K, sigma, r, T, year_rate, option_type)\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[1;32melse\u001B[0m \u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     22\u001B[0m         \u001B[1;31m# return K*np.exp(-r*T)*norm.cdf(-d2) - S*norm.cdf(-d1)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 23\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmaximum\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mK\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mS\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mT\u001B[0m\u001B[1;33m==\u001B[0m\u001B[1;36m0\u001B[0m \u001B[1;32melse\u001B[0m \u001B[0mK\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexp\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mT\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcdf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0md2\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m-\u001B[0m \u001B[0mS\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0mnorm\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mcdf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m-\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0md1\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     24\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     25\u001B[0m \u001B[1;32mdef\u001B[0m \u001B[0mbs_vega\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mS\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mK\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0msigma\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mr\u001B[0m\u001B[1;33m,\u001B[0m\u001B[0mT\u001B[0m \u001B[1;33m,\u001B[0m\u001B[0myear_rate\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m252\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mf:\\annacoda\\envs\\tensorflow\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py\u001B[0m in \u001B[0;36mcdf\u001B[1;34m(self, x, *args, **kwds)\u001B[0m\n\u001B[0;32m   1848\u001B[0m         \u001B[0mcond\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcond0\u001B[0m \u001B[1;33m&\u001B[0m \u001B[0mcond1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1849\u001B[0m         \u001B[0moutput\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mzeros\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mshape\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcond\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdtyp\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1850\u001B[1;33m         \u001B[0mplace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m1\u001B[0m\u001B[1;33m-\u001B[0m\u001B[0mcond0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m+\u001B[0m\u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0misnan\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mx\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mbadvalue\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1851\u001B[0m         \u001B[0mplace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0moutput\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcond2\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m1.0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1852\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0many\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcond\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m  \u001B[1;31m# call only if at least 1 entry\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mplace\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;32mf:\\annacoda\\envs\\tensorflow\\lib\\site-packages\\numpy\\lib\\function_base.py\u001B[0m in \u001B[0;36mplace\u001B[1;34m(arr, mask, vals)\u001B[0m\n\u001B[0;32m   1740\u001B[0m                         \"not {name}\".format(name=type(arr).__name__))\n\u001B[0;32m   1741\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1742\u001B[1;33m     \u001B[1;32mreturn\u001B[0m \u001B[0m_insert\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0marr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mmask\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvals\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1743\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1744\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "#数据处理\n",
    "alldata = []\n",
    "rate = pd.read_excel(r\".\\data\\unrisked_rate.xlsx\")\n",
    "rate['date'] = pd.to_datetime(rate['date'])\n",
    "rate['Value'] = rate['Value']/100\n",
    "\n",
    "etf50 = pd.read_excel(r'.\\data\\50etf_df.xlsx')\n",
    "etf50 = etf50[['Date','close']]\n",
    "etf50['Date'] = pd.to_datetime(etf50['Date'])\n",
    "\n",
    "csv_folder = r'.\\data\\50etf_option_data_csv'\n",
    "output_folder = r'.\\data\\out'\n",
    "csv_list = os.listdir(csv_folder)\n",
    "\n",
    "# ll = 1139\n",
    "for csv_name in csv_list:\n",
    "    print(csv_name)\n",
    "    '''ll -= 1\n",
    "    if ll > 0:\n",
    "        continue'''\n",
    "    perdata = []\n",
    "    csv_path = csv_folder +\"\\\\\"+csv_name\n",
    "    output_path = output_folder + \"\\\\\" + csv_name\n",
    "    data = pd.read_csv(csv_path, encoding = 'GBK', index_col= False)\n",
    "\n",
    "    data = data[['date','ptmtradeday','exe_price', 'open', 'high','low','close', 'call_or_put']]\n",
    "    data[\"date\"] = pd.to_datetime(data[\"date\"])\n",
    "    data['call_or_put'] = data['call_or_put'].apply(change)\n",
    "    if data['open'].dtype == 'object':\n",
    "        data.drop(data[data.open == '非数字'].index, inplace=True)\n",
    "\n",
    "    merged_option1 = pd.merge(rate, data, on = 'date', how = 'inner')\n",
    "    merged_option2 = pd.merge(etf50, merged_option1, left_on = 'Date', right_on = 'date', how = 'inner')\n",
    "    merged_option2 = merged_option2[['call_or_put','date','ptmtradeday','exe_price','Value', 'open', 'high','low','close_y','close_x']]\n",
    "    merged_option2.columns = ['call_or_put', 'date','ptmtradeday','k', 'rate', 'open', 'high','low','close','s']\n",
    "\n",
    "    for i in range(merged_option2.shape[0]):\n",
    "        merged_option2['close'][i] = float(merged_option2['close'][i])\n",
    "        tmp = iv_bs_bisection(np.array(merged_option2['s'][i]), np.array(merged_option2['k'][i]), np.array(merged_option2['rate'][i]), np.array(merged_option2['ptmtradeday'][i]), np.array(merged_option2['close'][i]), np.array(merged_option2['call_or_put'][i]))\n",
    "        if abs(tmp - 0.985) < 0.005 or abs(tmp - 0.015) < 0.005 or abs(tmp - 0.5) < 0.005:\n",
    "            if i == 0:\n",
    "                tmp = tmp\n",
    "            else:\n",
    "                tmp = perdata[i-1] + random.random()/100 - 0.005\n",
    "\n",
    "        perdata.append(tmp)\n",
    "\n",
    "    merged_option2['iv'] = perdata\n",
    "    merged_option2.to_csv(output_path)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000100.csv\n",
      "10000200.csv\n",
      "10000300.csv\n",
      "10000400.csv\n",
      "10000500.csv\n",
      "10000600.csv\n",
      "10000700.csv\n",
      "10000800.csv\n",
      "10000900.csv\n",
      "10001000.csv\n",
      "10001100.csv\n",
      "10001200.csv\n",
      "10001300.csv\n",
      "10001400.csv\n",
      "10001500.csv\n",
      "10001600.csv\n",
      "10001700.csv\n",
      "10001800.csv\n",
      "10001900.csv\n",
      "10002000.csv\n",
      "10002100.csv\n",
      "10002200.csv\n"
     ]
    }
   ],
   "source": [
    "#拼训练数据\n",
    "csv_folder = r'.\\data\\out'\n",
    "output_folder = r'.\\data'\n",
    "csv_list = os.listdir(csv_folder)\n",
    "output_path = output_folder + \"\\\\\" + 'final_data.csv'\n",
    "\n",
    "call_X = []\n",
    "call_Y = []\n",
    "put_X = []\n",
    "put_Y = []\n",
    "# 加一个混合\n",
    "# 做一个对比\n",
    "\n",
    "#numbers = 1139\n",
    "\n",
    "for csv_name in csv_list:\n",
    "    if int(csv_name.split('.')[0]) % 100 == 0:\n",
    "        print(csv_name)\n",
    "    perdata = []\n",
    "    '''numbers -= 1\n",
    "    if numbers == 0:\n",
    "        break'''\n",
    "    csv_path = csv_folder +\"\\\\\"+csv_name\n",
    "    data = pd.read_csv(csv_path, encoding = 'GBK', index_col= False)\n",
    "    if len(data) < 11:\n",
    "        continue\n",
    "\n",
    "    datatype = data['call_or_put'][0]\n",
    "    ll = 0\n",
    "\n",
    "    for i in range(len(data)-1):\n",
    "        onedata = list(data.iloc[i,3:])\n",
    "        perdata.append(onedata)\n",
    "        ll += 1\n",
    "        if ll == 10:\n",
    "            if datatype == 'call':\n",
    "                call_X.append(perdata)\n",
    "                call_Y.append(data['iv'][i+1])\n",
    "            else:\n",
    "                put_X.append(perdata)\n",
    "                put_Y.append(data['iv'][i+1])\n",
    "            ll -= 1\n",
    "            perdata = perdata[1:]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100100\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "teststring = '100100.csv'\n",
    "print(teststring.split('.')[0])\n",
    "print(int(teststring.split('.')[0]) % 100)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12075 0.002863931482325991\n",
      "12076 3.597375171640431e-05\n",
      "12076 9 8 0.002863931482325991\n",
      "12077 0.002978744117646342\n",
      "12077 8 8 0.002863931482325991\n",
      "12077 9 8 3.597375171640431e-05\n",
      "12078 0.00031855910399313387\n",
      "12078 7 8 0.002863931482325991\n",
      "12078 8 8 3.597375171640431e-05\n",
      "12078 9 8 0.002978744117646342\n",
      "12079 6 8 0.002863931482325991\n",
      "12079 7 8 3.597375171640431e-05\n",
      "12079 8 8 0.002978744117646342\n",
      "12079 9 8 0.00031855910399313387\n",
      "12080 5 8 0.002863931482325991\n",
      "12080 6 8 3.597375171640431e-05\n",
      "12080 7 8 0.002978744117646342\n",
      "12080 8 8 0.00031855910399313387\n",
      "12081 4 8 0.002863931482325991\n",
      "12081 5 8 3.597375171640431e-05\n",
      "12081 6 8 0.002978744117646342\n",
      "12081 7 8 0.00031855910399313387\n",
      "12082 3 8 0.002863931482325991\n",
      "12082 4 8 3.597375171640431e-05\n",
      "12082 5 8 0.002978744117646342\n",
      "12082 6 8 0.00031855910399313387\n",
      "12083 2 8 0.002863931482325991\n",
      "12083 3 8 3.597375171640431e-05\n",
      "12083 4 8 0.002978744117646342\n",
      "12083 5 8 0.00031855910399313387\n",
      "12084 1 8 0.002863931482325991\n",
      "12084 2 8 3.597375171640431e-05\n",
      "12084 3 8 0.002978744117646342\n",
      "12084 4 8 0.00031855910399313387\n",
      "12085 0 8 0.002863931482325991\n",
      "12085 1 8 3.597375171640431e-05\n",
      "12085 2 8 0.002978744117646342\n",
      "12085 3 8 0.00031855910399313387\n",
      "12086 0 8 3.597375171640431e-05\n",
      "12086 1 8 0.002978744117646342\n",
      "12086 2 8 0.00031855910399313387\n",
      "12087 0 8 0.002978744117646342\n",
      "12087 1 8 0.00031855910399313387\n",
      "12088 0 8 0.00031855910399313387\n",
      "12092 0.00410451302801813\n",
      "12093 0.0022583614552742887\n",
      "12093 9 8 0.00410451302801813\n",
      "12094 8 8 0.00410451302801813\n",
      "12094 9 8 0.0022583614552742887\n",
      "12095 0.0018486493395276629\n",
      "12095 7 8 0.00410451302801813\n",
      "12095 8 8 0.0022583614552742887\n",
      "12096 6 8 0.00410451302801813\n",
      "12096 7 8 0.0022583614552742887\n",
      "12096 9 8 0.0018486493395276629\n",
      "12097 5 8 0.00410451302801813\n",
      "12097 6 8 0.0022583614552742887\n",
      "12097 8 8 0.0018486493395276629\n",
      "26088 0.002444632882214589\n",
      "26089 0.0041192236361507545\n",
      "26089 9 8 0.002444632882214589\n",
      "26090 0.0063029172909151885\n",
      "26090 8 8 0.002444632882214589\n",
      "26090 9 8 0.0041192236361507545\n",
      "26091 0.0105671176136798\n",
      "26091 7 8 0.002444632882214589\n",
      "26091 8 8 0.0041192236361507545\n",
      "26091 9 8 0.0063029172909151885\n",
      "26092 0.011208978966149644\n",
      "26092 6 8 0.002444632882214589\n",
      "26092 7 8 0.0041192236361507545\n",
      "26092 8 8 0.0063029172909151885\n",
      "26092 9 8 0.0105671176136798\n",
      "26093 0.008586990037525236\n",
      "26093 5 8 0.002444632882214589\n",
      "26093 6 8 0.0041192236361507545\n",
      "26093 7 8 0.0063029172909151885\n",
      "26093 8 8 0.0105671176136798\n",
      "26093 9 8 0.011208978966149644\n",
      "26094 0.003985295886659248\n",
      "26094 4 8 0.002444632882214589\n",
      "26094 5 8 0.0041192236361507545\n",
      "26094 6 8 0.0063029172909151885\n",
      "26094 7 8 0.0105671176136798\n",
      "26094 8 8 0.011208978966149644\n",
      "26094 9 8 0.008586990037525236\n",
      "26095 3 8 0.002444632882214589\n",
      "26095 4 8 0.0041192236361507545\n",
      "26095 5 8 0.0063029172909151885\n",
      "26095 6 8 0.0105671176136798\n",
      "26095 7 8 0.011208978966149644\n",
      "26095 8 8 0.008586990037525236\n",
      "26095 9 8 0.003985295886659248\n",
      "26096 0.0045597483749452135\n",
      "26096 2 8 0.002444632882214589\n",
      "26096 3 8 0.0041192236361507545\n",
      "26096 4 8 0.0063029172909151885\n",
      "26096 5 8 0.0105671176136798\n",
      "26096 6 8 0.011208978966149644\n",
      "26096 7 8 0.008586990037525236\n",
      "26096 8 8 0.003985295886659248\n",
      "26097 0.008873733018374925\n",
      "26097 1 8 0.002444632882214589\n",
      "26097 2 8 0.0041192236361507545\n",
      "26097 3 8 0.0063029172909151885\n",
      "26097 4 8 0.0105671176136798\n",
      "26097 5 8 0.011208978966149644\n",
      "26097 6 8 0.008586990037525236\n",
      "26097 7 8 0.003985295886659248\n",
      "26097 9 8 0.0045597483749452135\n",
      "26098 0.011467441561402912\n",
      "26098 0 8 0.002444632882214589\n",
      "26098 1 8 0.0041192236361507545\n",
      "26098 2 8 0.0063029172909151885\n",
      "26098 3 8 0.0105671176136798\n",
      "26098 4 8 0.011208978966149644\n",
      "26098 5 8 0.008586990037525236\n",
      "26098 6 8 0.003985295886659248\n",
      "26098 8 8 0.0045597483749452135\n",
      "26098 9 8 0.008873733018374925\n",
      "26099 0.009496102602602042\n",
      "26099 0 8 0.0041192236361507545\n",
      "26099 1 8 0.0063029172909151885\n",
      "26099 2 8 0.0105671176136798\n",
      "26099 3 8 0.011208978966149644\n",
      "26099 4 8 0.008586990037525236\n",
      "26099 5 8 0.003985295886659248\n",
      "26099 7 8 0.0045597483749452135\n",
      "26099 8 8 0.008873733018374925\n",
      "26099 9 8 0.011467441561402912\n",
      "26100 0.008604029219856759\n",
      "26100 0 8 0.0063029172909151885\n",
      "26100 1 8 0.0105671176136798\n",
      "26100 2 8 0.011208978966149644\n",
      "26100 3 8 0.008586990037525236\n",
      "26100 4 8 0.003985295886659248\n",
      "26100 6 8 0.0045597483749452135\n",
      "26100 7 8 0.008873733018374925\n",
      "26100 8 8 0.011467441561402912\n",
      "26100 9 8 0.009496102602602042\n",
      "26101 0.004631126696889496\n",
      "26101 0 8 0.0105671176136798\n",
      "26101 1 8 0.011208978966149644\n",
      "26101 2 8 0.008586990037525236\n",
      "26101 3 8 0.003985295886659248\n",
      "26101 5 8 0.0045597483749452135\n",
      "26101 6 8 0.008873733018374925\n",
      "26101 7 8 0.011467441561402912\n",
      "26101 8 8 0.009496102602602042\n",
      "26101 9 8 0.008604029219856759\n",
      "26102 0.00416382105174042\n",
      "26102 0 8 0.011208978966149644\n",
      "26102 1 8 0.008586990037525236\n",
      "26102 2 8 0.003985295886659248\n",
      "26102 4 8 0.0045597483749452135\n",
      "26102 5 8 0.008873733018374925\n",
      "26102 6 8 0.011467441561402912\n",
      "26102 7 8 0.009496102602602042\n",
      "26102 8 8 0.008604029219856759\n",
      "26102 9 8 0.004631126696889496\n",
      "26103 0.0050535742168587435\n",
      "26103 0 8 0.008586990037525236\n",
      "26103 1 8 0.003985295886659248\n",
      "26103 3 8 0.0045597483749452135\n",
      "26103 4 8 0.008873733018374925\n",
      "26103 5 8 0.011467441561402912\n",
      "26103 6 8 0.009496102602602042\n",
      "26103 7 8 0.008604029219856759\n",
      "26103 8 8 0.004631126696889496\n",
      "26103 9 8 0.00416382105174042\n",
      "26104 0.010027647453023569\n",
      "26104 0 8 0.003985295886659248\n",
      "26104 2 8 0.0045597483749452135\n",
      "26104 3 8 0.008873733018374925\n",
      "26104 4 8 0.011467441561402912\n",
      "26104 5 8 0.009496102602602042\n",
      "26104 6 8 0.008604029219856759\n",
      "26104 7 8 0.004631126696889496\n",
      "26104 8 8 0.00416382105174042\n",
      "26104 9 8 0.0050535742168587435\n",
      "26105 0.0074929663029767515\n",
      "26105 1 8 0.0045597483749452135\n",
      "26105 2 8 0.008873733018374925\n",
      "26105 3 8 0.011467441561402912\n",
      "26105 4 8 0.009496102602602042\n",
      "26105 5 8 0.008604029219856759\n",
      "26105 6 8 0.004631126696889496\n",
      "26105 7 8 0.00416382105174042\n",
      "26105 8 8 0.0050535742168587435\n",
      "26105 9 8 0.010027647453023569\n",
      "26106 0.006984611487050678\n",
      "26106 0 8 0.0045597483749452135\n",
      "26106 1 8 0.008873733018374925\n",
      "26106 2 8 0.011467441561402912\n",
      "26106 3 8 0.009496102602602042\n",
      "26106 4 8 0.008604029219856759\n",
      "26106 5 8 0.004631126696889496\n",
      "26106 6 8 0.00416382105174042\n",
      "26106 7 8 0.0050535742168587435\n",
      "26106 8 8 0.010027647453023569\n",
      "26106 9 8 0.0074929663029767515\n",
      "26107 0.0052661268884826\n",
      "26107 0 8 0.008873733018374925\n",
      "26107 1 8 0.011467441561402912\n",
      "26107 2 8 0.009496102602602042\n",
      "26107 3 8 0.008604029219856759\n",
      "26107 4 8 0.004631126696889496\n",
      "26107 5 8 0.00416382105174042\n",
      "26107 6 8 0.0050535742168587435\n",
      "26107 7 8 0.010027647453023569\n",
      "26107 8 8 0.0074929663029767515\n",
      "26107 9 8 0.006984611487050678\n",
      "26108 0.00966071213233674\n",
      "26108 0 8 0.011467441561402912\n",
      "26108 1 8 0.009496102602602042\n",
      "26108 2 8 0.008604029219856759\n",
      "26108 3 8 0.004631126696889496\n",
      "26108 4 8 0.00416382105174042\n",
      "26108 5 8 0.0050535742168587435\n",
      "26108 6 8 0.010027647453023569\n",
      "26108 7 8 0.0074929663029767515\n",
      "26108 8 8 0.006984611487050678\n",
      "26108 9 8 0.0052661268884826\n",
      "26109 0.010932263572786741\n",
      "26109 0 8 0.009496102602602042\n",
      "26109 1 8 0.008604029219856759\n",
      "26109 2 8 0.004631126696889496\n",
      "26109 3 8 0.00416382105174042\n",
      "26109 4 8 0.0050535742168587435\n",
      "26109 5 8 0.010027647453023569\n",
      "26109 6 8 0.0074929663029767515\n",
      "26109 7 8 0.006984611487050678\n",
      "26109 8 8 0.0052661268884826\n",
      "26109 9 8 0.00966071213233674\n",
      "26110 0.008015958097050744\n",
      "26110 0 8 0.008604029219856759\n",
      "26110 1 8 0.004631126696889496\n",
      "26110 2 8 0.00416382105174042\n",
      "26110 3 8 0.0050535742168587435\n",
      "26110 4 8 0.010027647453023569\n",
      "26110 5 8 0.0074929663029767515\n",
      "26110 6 8 0.006984611487050678\n",
      "26110 7 8 0.0052661268884826\n",
      "26110 8 8 0.00966071213233674\n",
      "26110 9 8 0.010932263572786741\n",
      "26111 0.0033319373827403486\n",
      "26111 0 8 0.004631126696889496\n",
      "26111 1 8 0.00416382105174042\n",
      "26111 2 8 0.0050535742168587435\n",
      "26111 3 8 0.010027647453023569\n",
      "26111 4 8 0.0074929663029767515\n",
      "26111 5 8 0.006984611487050678\n",
      "26111 6 8 0.0052661268884826\n",
      "26111 7 8 0.00966071213233674\n",
      "26111 8 8 0.010932263572786741\n",
      "26111 9 8 0.008015958097050744\n",
      "26112 0.0021200414455290963\n",
      "26112 0 8 0.00416382105174042\n",
      "26112 1 8 0.0050535742168587435\n",
      "26112 2 8 0.010027647453023569\n",
      "26112 3 8 0.0074929663029767515\n",
      "26112 4 8 0.006984611487050678\n",
      "26112 5 8 0.0052661268884826\n",
      "26112 6 8 0.00966071213233674\n",
      "26112 7 8 0.010932263572786741\n",
      "26112 8 8 0.008015958097050744\n",
      "26112 9 8 0.0033319373827403486\n",
      "26113 0.005911311006955425\n",
      "26113 0 8 0.0050535742168587435\n",
      "26113 1 8 0.010027647453023569\n",
      "26113 2 8 0.0074929663029767515\n",
      "26113 3 8 0.006984611487050678\n",
      "26113 4 8 0.0052661268884826\n",
      "26113 5 8 0.00966071213233674\n",
      "26113 6 8 0.010932263572786741\n",
      "26113 7 8 0.008015958097050744\n",
      "26113 8 8 0.0033319373827403486\n",
      "26113 9 8 0.0021200414455290963\n",
      "26114 0.004679236087030832\n",
      "26114 0 8 0.010027647453023569\n",
      "26114 1 8 0.0074929663029767515\n",
      "26114 2 8 0.006984611487050678\n",
      "26114 3 8 0.0052661268884826\n",
      "26114 4 8 0.00966071213233674\n",
      "26114 5 8 0.010932263572786741\n",
      "26114 6 8 0.008015958097050744\n",
      "26114 7 8 0.0033319373827403486\n",
      "26114 8 8 0.0021200414455290963\n",
      "26114 9 8 0.005911311006955425\n",
      "26115 0.0021272450150529357\n",
      "26115 0 8 0.0074929663029767515\n",
      "26115 1 8 0.006984611487050678\n",
      "26115 2 8 0.0052661268884826\n",
      "26115 3 8 0.00966071213233674\n",
      "26115 4 8 0.010932263572786741\n",
      "26115 5 8 0.008015958097050744\n",
      "26115 6 8 0.0033319373827403486\n",
      "26115 7 8 0.0021200414455290963\n",
      "26115 8 8 0.005911311006955425\n",
      "26115 9 8 0.004679236087030832\n",
      "26116 0 8 0.006984611487050678\n",
      "26116 1 8 0.0052661268884826\n",
      "26116 2 8 0.00966071213233674\n",
      "26116 3 8 0.010932263572786741\n",
      "26116 4 8 0.008015958097050744\n",
      "26116 5 8 0.0033319373827403486\n",
      "26116 6 8 0.0021200414455290963\n",
      "26116 7 8 0.005911311006955425\n",
      "26116 8 8 0.004679236087030832\n",
      "26116 9 8 0.0021272450150529357\n",
      "26117 0.001537147005922669\n",
      "26117 0 8 0.0052661268884826\n",
      "26117 1 8 0.00966071213233674\n",
      "26117 2 8 0.010932263572786741\n",
      "26117 3 8 0.008015958097050744\n",
      "26117 4 8 0.0033319373827403486\n",
      "26117 5 8 0.0021200414455290963\n",
      "26117 6 8 0.005911311006955425\n",
      "26117 7 8 0.004679236087030832\n",
      "26117 8 8 0.0021272450150529357\n",
      "26118 0.002771434737149885\n",
      "26118 0 8 0.00966071213233674\n",
      "26118 1 8 0.010932263572786741\n",
      "26118 2 8 0.008015958097050744\n",
      "26118 3 8 0.0033319373827403486\n",
      "26118 4 8 0.0021200414455290963\n",
      "26118 5 8 0.005911311006955425\n",
      "26118 6 8 0.004679236087030832\n",
      "26118 7 8 0.0021272450150529357\n",
      "26118 9 8 0.001537147005922669\n",
      "26119 0 8 0.010932263572786741\n",
      "26119 1 8 0.008015958097050744\n",
      "26119 2 8 0.0033319373827403486\n",
      "26119 3 8 0.0021200414455290963\n",
      "26119 4 8 0.005911311006955425\n",
      "26119 5 8 0.004679236087030832\n",
      "26119 6 8 0.0021272450150529357\n",
      "26119 8 8 0.001537147005922669\n",
      "26119 9 8 0.002771434737149885\n",
      "26120 0 8 0.008015958097050744\n",
      "26120 1 8 0.0033319373827403486\n",
      "26120 2 8 0.0021200414455290963\n",
      "26120 3 8 0.005911311006955425\n",
      "26120 4 8 0.004679236087030832\n",
      "26120 5 8 0.0021272450150529357\n",
      "26120 7 8 0.001537147005922669\n",
      "26120 8 8 0.002771434737149885\n",
      "26121 0 8 0.0033319373827403486\n",
      "26121 1 8 0.0021200414455290963\n",
      "26121 2 8 0.005911311006955425\n",
      "26121 3 8 0.004679236087030832\n",
      "26121 4 8 0.0021272450150529357\n",
      "26121 6 8 0.001537147005922669\n",
      "26121 7 8 0.002771434737149885\n",
      "26122 0 8 0.0021200414455290963\n",
      "26122 1 8 0.005911311006955425\n",
      "26122 2 8 0.004679236087030832\n",
      "26122 3 8 0.0021272450150529357\n",
      "26122 5 8 0.001537147005922669\n",
      "26122 6 8 0.002771434737149885\n",
      "26123 0 8 0.005911311006955425\n",
      "26123 1 8 0.004679236087030832\n",
      "26123 2 8 0.0021272450150529357\n",
      "26123 4 8 0.001537147005922669\n",
      "26123 5 8 0.002771434737149885\n",
      "26124 0 8 0.004679236087030832\n",
      "26124 1 8 0.0021272450150529357\n",
      "26124 3 8 0.001537147005922669\n",
      "26124 4 8 0.002771434737149885\n",
      "26125 0 8 0.0021272450150529357\n",
      "26125 2 8 0.001537147005922669\n",
      "26125 3 8 0.002771434737149885\n",
      "26126 1 8 0.001537147005922669\n",
      "26126 2 8 0.002771434737149885\n",
      "26127 0 8 0.001537147005922669\n",
      "26127 1 8 0.002771434737149885\n",
      "26128 0 8 0.002771434737149885\n",
      "26866 0.005550574451149473\n",
      "26866 7 8 0.003982829192535521\n",
      "26866 8 8 0.0047279897165043005\n",
      "26866 9 8 0.0010386569367121497\n",
      "26867 0.008802778664734742\n",
      "26867 6 8 0.003982829192535521\n",
      "26867 7 8 0.0047279897165043005\n",
      "26867 8 8 0.0010386569367121497\n",
      "26867 9 8 0.005550574451149473\n",
      "26868 0.006178709259024899\n",
      "26868 5 8 0.003982829192535521\n",
      "26868 6 8 0.0047279897165043005\n",
      "26868 7 8 0.0010386569367121497\n",
      "26868 8 8 0.005550574451149473\n",
      "26868 9 8 0.008802778664734742\n",
      "26869 0.007172305865528755\n",
      "26869 4 8 0.003982829192535521\n",
      "26869 5 8 0.0047279897165043005\n",
      "26869 6 8 0.0010386569367121497\n",
      "26869 7 8 0.005550574451149473\n",
      "26869 8 8 0.008802778664734742\n",
      "26869 9 8 0.006178709259024899\n",
      "26870 0.011299398463382586\n",
      "26870 3 8 0.003982829192535521\n",
      "26870 4 8 0.0047279897165043005\n",
      "26870 5 8 0.0010386569367121497\n",
      "26870 6 8 0.005550574451149473\n",
      "26870 7 8 0.008802778664734742\n",
      "26870 8 8 0.006178709259024899\n",
      "26870 9 8 0.007172305865528755\n",
      "26871 0.014515491611296356\n",
      "26871 2 8 0.003982829192535521\n",
      "26871 3 8 0.0047279897165043005\n",
      "26871 4 8 0.0010386569367121497\n",
      "26871 5 8 0.005550574451149473\n",
      "26871 6 8 0.008802778664734742\n",
      "26871 7 8 0.006178709259024899\n",
      "26871 8 8 0.007172305865528755\n",
      "26871 9 8 0.011299398463382586\n",
      "26872 0.011137440693376565\n",
      "26872 1 8 0.003982829192535521\n",
      "26872 2 8 0.0047279897165043005\n",
      "26872 3 8 0.0010386569367121497\n",
      "26872 4 8 0.005550574451149473\n",
      "26872 5 8 0.008802778664734742\n",
      "26872 6 8 0.006178709259024899\n",
      "26872 7 8 0.007172305865528755\n",
      "26872 8 8 0.011299398463382586\n",
      "26872 9 8 0.014515491611296356\n",
      "26873 0.010371157161425608\n",
      "26873 0 8 0.003982829192535521\n",
      "26873 1 8 0.0047279897165043005\n",
      "26873 2 8 0.0010386569367121497\n",
      "26873 3 8 0.005550574451149473\n",
      "26873 4 8 0.008802778664734742\n",
      "26873 5 8 0.006178709259024899\n",
      "26873 6 8 0.007172305865528755\n",
      "26873 7 8 0.011299398463382586\n",
      "26873 8 8 0.014515491611296356\n",
      "26873 9 8 0.011137440693376565\n",
      "26874 0.008830791408992275\n",
      "26874 0 8 0.0047279897165043005\n",
      "26874 1 8 0.0010386569367121497\n",
      "26874 2 8 0.005550574451149473\n",
      "26874 3 8 0.008802778664734742\n",
      "26874 4 8 0.006178709259024899\n",
      "26874 5 8 0.007172305865528755\n",
      "26874 6 8 0.011299398463382586\n",
      "26874 7 8 0.014515491611296356\n",
      "26874 8 8 0.011137440693376565\n",
      "26874 9 8 0.010371157161425608\n",
      "26875 0.012193773031772964\n",
      "26875 0 8 0.0010386569367121497\n",
      "26875 1 8 0.005550574451149473\n",
      "26875 2 8 0.008802778664734742\n",
      "26875 3 8 0.006178709259024899\n",
      "26875 4 8 0.007172305865528755\n",
      "26875 5 8 0.011299398463382586\n",
      "26875 6 8 0.014515491611296356\n",
      "26875 7 8 0.011137440693376565\n",
      "26875 8 8 0.010371157161425608\n",
      "26875 9 8 0.008830791408992275\n",
      "26876 0.013424380812504456\n",
      "26876 0 8 0.005550574451149473\n",
      "26876 1 8 0.008802778664734742\n",
      "26876 2 8 0.006178709259024899\n",
      "26876 3 8 0.007172305865528755\n",
      "26876 4 8 0.011299398463382586\n",
      "26876 5 8 0.014515491611296356\n",
      "26876 6 8 0.011137440693376565\n",
      "26876 7 8 0.010371157161425608\n",
      "26876 8 8 0.008830791408992275\n",
      "26876 9 8 0.012193773031772964\n",
      "26877 0.010411997606678734\n",
      "26877 0 8 0.008802778664734742\n",
      "26877 1 8 0.006178709259024899\n",
      "26877 2 8 0.007172305865528755\n",
      "26877 3 8 0.011299398463382586\n",
      "26877 4 8 0.014515491611296356\n",
      "26877 5 8 0.011137440693376565\n",
      "26877 6 8 0.010371157161425608\n",
      "26877 7 8 0.008830791408992275\n",
      "26877 8 8 0.012193773031772964\n",
      "26877 9 8 0.013424380812504456\n",
      "26878 0.0077799425532862985\n",
      "26878 0 8 0.006178709259024899\n",
      "26878 1 8 0.007172305865528755\n",
      "26878 2 8 0.011299398463382586\n",
      "26878 3 8 0.014515491611296356\n",
      "26878 4 8 0.011137440693376565\n",
      "26878 5 8 0.010371157161425608\n",
      "26878 6 8 0.008830791408992275\n",
      "26878 7 8 0.012193773031772964\n",
      "26878 8 8 0.013424380812504456\n",
      "26878 9 8 0.010411997606678734\n",
      "26879 0.010747409132318432\n",
      "26879 0 8 0.007172305865528755\n",
      "26879 1 8 0.011299398463382586\n",
      "26879 2 8 0.014515491611296356\n",
      "26879 3 8 0.011137440693376565\n",
      "26879 4 8 0.010371157161425608\n",
      "26879 5 8 0.008830791408992275\n",
      "26879 6 8 0.012193773031772964\n",
      "26879 7 8 0.013424380812504456\n",
      "26879 8 8 0.010411997606678734\n",
      "26879 9 8 0.0077799425532862985\n",
      "26880 0.007871348769254723\n",
      "26880 0 8 0.011299398463382586\n",
      "26880 1 8 0.014515491611296356\n",
      "26880 2 8 0.011137440693376565\n",
      "26880 3 8 0.010371157161425608\n",
      "26880 4 8 0.008830791408992275\n",
      "26880 5 8 0.012193773031772964\n",
      "26880 6 8 0.013424380812504456\n",
      "26880 7 8 0.010411997606678734\n",
      "26880 8 8 0.0077799425532862985\n",
      "26880 9 8 0.010747409132318432\n",
      "26881 0.005445629027409179\n",
      "26881 0 8 0.014515491611296356\n",
      "26881 1 8 0.011137440693376565\n",
      "26881 2 8 0.010371157161425608\n",
      "26881 3 8 0.008830791408992275\n",
      "26881 4 8 0.012193773031772964\n",
      "26881 5 8 0.013424380812504456\n",
      "26881 6 8 0.010411997606678734\n",
      "26881 7 8 0.0077799425532862985\n",
      "26881 8 8 0.010747409132318432\n",
      "26881 9 8 0.007871348769254723\n",
      "26882 0.002440437656679874\n",
      "26882 0 8 0.011137440693376565\n",
      "26882 1 8 0.010371157161425608\n",
      "26882 2 8 0.008830791408992275\n",
      "26882 3 8 0.012193773031772964\n",
      "26882 4 8 0.013424380812504456\n",
      "26882 5 8 0.010411997606678734\n",
      "26882 6 8 0.0077799425532862985\n",
      "26882 7 8 0.010747409132318432\n",
      "26882 8 8 0.007871348769254723\n",
      "26882 9 8 0.005445629027409179\n",
      "26883 0.006893301945355285\n",
      "26883 0 8 0.010371157161425608\n",
      "26883 1 8 0.008830791408992275\n",
      "26883 2 8 0.012193773031772964\n",
      "26883 3 8 0.013424380812504456\n",
      "26883 4 8 0.010411997606678734\n",
      "26883 5 8 0.0077799425532862985\n",
      "26883 6 8 0.010747409132318432\n",
      "26883 7 8 0.007871348769254723\n",
      "26883 8 8 0.005445629027409179\n",
      "26883 9 8 0.002440437656679874\n",
      "26884 0.0021303456045402287\n",
      "26884 0 8 0.008830791408992275\n",
      "26884 1 8 0.012193773031772964\n",
      "26884 2 8 0.013424380812504456\n",
      "26884 3 8 0.010411997606678734\n",
      "26884 4 8 0.0077799425532862985\n",
      "26884 5 8 0.010747409132318432\n",
      "26884 6 8 0.007871348769254723\n",
      "26884 7 8 0.005445629027409179\n",
      "26884 8 8 0.002440437656679874\n",
      "26884 9 8 0.006893301945355285\n",
      "26885 0.002485256047121516\n",
      "26885 0 8 0.012193773031772964\n",
      "26885 1 8 0.013424380812504456\n",
      "26885 2 8 0.010411997606678734\n",
      "26885 3 8 0.0077799425532862985\n",
      "26885 4 8 0.010747409132318432\n",
      "26885 5 8 0.007871348769254723\n",
      "26885 6 8 0.005445629027409179\n",
      "26885 7 8 0.002440437656679874\n",
      "26885 8 8 0.006893301945355285\n",
      "26885 9 8 0.0021303456045402287\n",
      "26886 0.006881786995214879\n",
      "26886 0 8 0.013424380812504456\n",
      "26886 1 8 0.010411997606678734\n",
      "26886 2 8 0.0077799425532862985\n",
      "26886 3 8 0.010747409132318432\n",
      "26886 4 8 0.007871348769254723\n",
      "26886 5 8 0.005445629027409179\n",
      "26886 6 8 0.002440437656679874\n",
      "26886 7 8 0.006893301945355285\n",
      "26886 8 8 0.0021303456045402287\n",
      "26886 9 8 0.002485256047121516\n",
      "26887 0.00993469635685978\n",
      "26887 0 8 0.010411997606678734\n",
      "26887 1 8 0.0077799425532862985\n",
      "26887 2 8 0.010747409132318432\n",
      "26887 3 8 0.007871348769254723\n",
      "26887 4 8 0.005445629027409179\n",
      "26887 5 8 0.002440437656679874\n",
      "26887 6 8 0.006893301945355285\n",
      "26887 7 8 0.0021303456045402287\n",
      "26887 8 8 0.002485256047121516\n",
      "26887 9 8 0.006881786995214879\n",
      "26888 0.007972592100319306\n",
      "26888 0 8 0.0077799425532862985\n",
      "26888 1 8 0.010747409132318432\n",
      "26888 2 8 0.007871348769254723\n",
      "26888 3 8 0.005445629027409179\n",
      "26888 4 8 0.002440437656679874\n",
      "26888 5 8 0.006893301945355285\n",
      "26888 6 8 0.0021303456045402287\n",
      "26888 7 8 0.002485256047121516\n",
      "26888 8 8 0.006881786995214879\n",
      "26888 9 8 0.00993469635685978\n",
      "26889 0.004553827408944386\n",
      "26889 0 8 0.010747409132318432\n",
      "26889 1 8 0.007871348769254723\n",
      "26889 2 8 0.005445629027409179\n",
      "26889 3 8 0.002440437656679874\n",
      "26889 4 8 0.006893301945355285\n",
      "26889 5 8 0.0021303456045402287\n",
      "26889 6 8 0.002485256047121516\n",
      "26889 7 8 0.006881786995214879\n",
      "26889 8 8 0.00993469635685978\n",
      "26889 9 8 0.007972592100319306\n",
      "26890 0.0031696465380882397\n",
      "26890 0 8 0.007871348769254723\n",
      "26890 1 8 0.005445629027409179\n",
      "26890 2 8 0.002440437656679874\n",
      "26890 3 8 0.006893301945355285\n",
      "26890 4 8 0.0021303456045402287\n",
      "26890 5 8 0.002485256047121516\n",
      "26890 6 8 0.006881786995214879\n",
      "26890 7 8 0.00993469635685978\n",
      "26890 8 8 0.007972592100319306\n",
      "26890 9 8 0.004553827408944386\n",
      "26891 0 8 0.005445629027409179\n",
      "26891 1 8 0.002440437656679874\n",
      "26891 2 8 0.006893301945355285\n",
      "26891 3 8 0.0021303456045402287\n",
      "26891 4 8 0.002485256047121516\n",
      "26891 5 8 0.006881786995214879\n",
      "26891 6 8 0.00993469635685978\n",
      "26891 7 8 0.007972592100319306\n",
      "26891 8 8 0.004553827408944386\n",
      "26891 9 8 0.0031696465380882397\n",
      "26892 0.0007638635538925673\n",
      "26892 0 8 0.002440437656679874\n",
      "26892 1 8 0.006893301945355285\n",
      "26892 2 8 0.0021303456045402287\n",
      "26892 3 8 0.002485256047121516\n",
      "26892 4 8 0.006881786995214879\n",
      "26892 5 8 0.00993469635685978\n",
      "26892 6 8 0.007972592100319306\n",
      "26892 7 8 0.004553827408944386\n",
      "26892 8 8 0.0031696465380882397\n",
      "26893 0 8 0.006893301945355285\n",
      "26893 1 8 0.0021303456045402287\n",
      "26893 2 8 0.002485256047121516\n",
      "26893 3 8 0.006881786995214879\n",
      "26893 4 8 0.00993469635685978\n",
      "26893 5 8 0.007972592100319306\n",
      "26893 6 8 0.004553827408944386\n",
      "26893 7 8 0.0031696465380882397\n",
      "26893 9 8 0.0007638635538925673\n",
      "26894 0.0008541285626876335\n",
      "26894 0 8 0.0021303456045402287\n",
      "26894 1 8 0.002485256047121516\n",
      "26894 2 8 0.006881786995214879\n",
      "26894 3 8 0.00993469635685978\n",
      "26894 4 8 0.007972592100319306\n",
      "26894 5 8 0.004553827408944386\n",
      "26894 6 8 0.0031696465380882397\n",
      "26894 8 8 0.0007638635538925673\n",
      "26895 0 8 0.002485256047121516\n",
      "26895 1 8 0.006881786995214879\n",
      "26895 2 8 0.00993469635685978\n",
      "26895 3 8 0.007972592100319306\n",
      "26895 4 8 0.004553827408944386\n",
      "26895 5 8 0.0031696465380882397\n",
      "26895 7 8 0.0007638635538925673\n",
      "26895 9 8 0.0008541285626876335\n",
      "26896 0 8 0.006881786995214879\n",
      "26896 1 8 0.00993469635685978\n",
      "26896 2 8 0.007972592100319306\n",
      "26896 3 8 0.004553827408944386\n",
      "26896 4 8 0.0031696465380882397\n",
      "26896 6 8 0.0007638635538925673\n",
      "26896 8 8 0.0008541285626876335\n",
      "26897 0 8 0.00993469635685978\n",
      "26897 1 8 0.007972592100319306\n",
      "26897 2 8 0.004553827408944386\n",
      "26897 3 8 0.0031696465380882397\n",
      "26897 5 8 0.0007638635538925673\n",
      "26897 7 8 0.0008541285626876335\n",
      "26898 0 8 0.007972592100319306\n",
      "26898 1 8 0.004553827408944386\n",
      "26898 2 8 0.0031696465380882397\n",
      "26898 4 8 0.0007638635538925673\n",
      "26898 6 8 0.0008541285626876335\n",
      "26899 0 8 0.004553827408944386\n",
      "26899 1 8 0.0031696465380882397\n",
      "26899 3 8 0.0007638635538925673\n",
      "26899 5 8 0.0008541285626876335\n",
      "26900 0.001544062233646802\n",
      "26900 0 8 0.0031696465380882397\n",
      "26900 2 8 0.0007638635538925673\n",
      "26900 4 8 0.0008541285626876335\n",
      "26901 0.005405674131260108\n",
      "26901 1 8 0.0007638635538925673\n",
      "26901 3 8 0.0008541285626876335\n",
      "26901 9 8 0.001544062233646802\n",
      "26902 0.0025006016342217986\n",
      "26902 0 8 0.0007638635538925673\n",
      "26902 2 8 0.0008541285626876335\n",
      "26902 8 8 0.001544062233646802\n",
      "26902 9 8 0.005405674131260108\n",
      "26903 0.006960497265395412\n",
      "26903 1 8 0.0008541285626876335\n",
      "26903 7 8 0.001544062233646802\n",
      "26903 8 8 0.005405674131260108\n",
      "26903 9 8 0.0025006016342217986\n",
      "26904 0.011176086304775313\n",
      "26904 0 8 0.0008541285626876335\n",
      "26904 6 8 0.001544062233646802\n",
      "26904 7 8 0.005405674131260108\n",
      "26904 8 8 0.0025006016342217986\n",
      "26904 9 8 0.006960497265395412\n",
      "26905 0.014589104932509225\n",
      "26905 5 8 0.001544062233646802\n",
      "26905 6 8 0.005405674131260108\n",
      "26905 7 8 0.0025006016342217986\n",
      "26905 8 8 0.006960497265395412\n",
      "26905 9 8 0.011176086304775313\n",
      "26906 0.016873050524617628\n",
      "26906 4 8 0.001544062233646802\n",
      "26906 5 8 0.005405674131260108\n",
      "26906 6 8 0.0025006016342217986\n",
      "26906 7 8 0.006960497265395412\n",
      "26906 8 8 0.011176086304775313\n",
      "26906 9 8 0.014589104932509225\n",
      "26907 0.019490937085358054\n",
      "26907 3 8 0.001544062233646802\n",
      "26907 4 8 0.005405674131260108\n",
      "26907 5 8 0.0025006016342217986\n",
      "26907 6 8 0.006960497265395412\n",
      "26907 7 8 0.011176086304775313\n",
      "26907 8 8 0.014589104932509225\n",
      "26907 9 8 0.016873050524617628\n",
      "26908 0.019830807313902132\n",
      "26908 2 8 0.001544062233646802\n",
      "26908 3 8 0.005405674131260108\n",
      "26908 4 8 0.0025006016342217986\n",
      "26908 5 8 0.006960497265395412\n",
      "26908 6 8 0.011176086304775313\n",
      "26908 7 8 0.014589104932509225\n",
      "26908 8 8 0.016873050524617628\n",
      "26908 9 8 0.019490937085358054\n",
      "26909 0.018498444348780282\n",
      "26909 1 8 0.001544062233646802\n",
      "26909 2 8 0.005405674131260108\n",
      "26909 3 8 0.0025006016342217986\n",
      "26909 4 8 0.006960497265395412\n",
      "26909 5 8 0.011176086304775313\n",
      "26909 6 8 0.014589104932509225\n",
      "26909 7 8 0.016873050524617628\n",
      "26909 8 8 0.019490937085358054\n",
      "26909 9 8 0.019830807313902132\n",
      "26910 0.017109673614448272\n",
      "26910 0 8 0.001544062233646802\n",
      "26910 1 8 0.005405674131260108\n",
      "26910 2 8 0.0025006016342217986\n",
      "26910 3 8 0.006960497265395412\n",
      "26910 4 8 0.011176086304775313\n",
      "26910 5 8 0.014589104932509225\n",
      "26910 6 8 0.016873050524617628\n",
      "26910 7 8 0.019490937085358054\n",
      "26910 8 8 0.019830807313902132\n",
      "26910 9 8 0.018498444348780282\n",
      "26911 0 8 0.005405674131260108\n",
      "26911 1 8 0.0025006016342217986\n",
      "26911 2 8 0.006960497265395412\n",
      "26911 3 8 0.011176086304775313\n",
      "26911 4 8 0.014589104932509225\n",
      "26911 5 8 0.016873050524617628\n",
      "26911 6 8 0.019490937085358054\n",
      "26911 7 8 0.019830807313902132\n",
      "26911 8 8 0.018498444348780282\n",
      "26911 9 8 0.017109673614448272\n",
      "26912 0 8 0.0025006016342217986\n",
      "26912 1 8 0.006960497265395412\n",
      "26912 2 8 0.011176086304775313\n",
      "26912 3 8 0.014589104932509225\n",
      "26912 4 8 0.016873050524617628\n",
      "26912 5 8 0.019490937085358054\n",
      "26912 6 8 0.019830807313902132\n",
      "26912 7 8 0.018498444348780282\n",
      "26912 8 8 0.017109673614448272\n",
      "26913 0 8 0.006960497265395412\n",
      "26913 1 8 0.011176086304775313\n",
      "26913 2 8 0.014589104932509225\n",
      "26913 3 8 0.016873050524617628\n",
      "26913 4 8 0.019490937085358054\n",
      "26913 5 8 0.019830807313902132\n",
      "26913 6 8 0.018498444348780282\n",
      "26913 7 8 0.017109673614448272\n",
      "26914 0 8 0.011176086304775313\n",
      "26914 1 8 0.014589104932509225\n",
      "26914 2 8 0.016873050524617628\n",
      "26914 3 8 0.019490937085358054\n",
      "26914 4 8 0.019830807313902132\n",
      "26914 5 8 0.018498444348780282\n",
      "26914 6 8 0.017109673614448272\n",
      "26915 0 8 0.014589104932509225\n",
      "26915 1 8 0.016873050524617628\n",
      "26915 2 8 0.019490937085358054\n",
      "26915 3 8 0.019830807313902132\n",
      "26915 4 8 0.018498444348780282\n",
      "26915 5 8 0.017109673614448272\n",
      "26916 0 8 0.016873050524617628\n",
      "26916 1 8 0.019490937085358054\n",
      "26916 2 8 0.019830807313902132\n",
      "26916 3 8 0.018498444348780282\n",
      "26916 4 8 0.017109673614448272\n",
      "26917 0 8 0.019490937085358054\n",
      "26917 1 8 0.019830807313902132\n",
      "26917 2 8 0.018498444348780282\n",
      "26917 3 8 0.017109673614448272\n",
      "26918 0 8 0.019830807313902132\n",
      "26918 1 8 0.018498444348780282\n",
      "26918 2 8 0.017109673614448272\n",
      "26919 0 8 0.018498444348780282\n",
      "26919 1 8 0.017109673614448272\n",
      "26920 0 8 0.017109673614448272\n",
      "67121 0.000728140990011404\n",
      "67122 0.0004744317544034754\n",
      "67122 9 8 0.000728140990011404\n",
      "67123 8 8 0.000728140990011404\n",
      "67123 9 8 0.0004744317544034754\n",
      "67124 7 8 0.000728140990011404\n",
      "67124 8 8 0.0004744317544034754\n",
      "67125 6 8 0.000728140990011404\n",
      "67125 7 8 0.0004744317544034754\n",
      "67126 5 8 0.000728140990011404\n",
      "67126 6 8 0.0004744317544034754\n",
      "67127 4 8 0.000728140990011404\n",
      "67127 5 8 0.0004744317544034754\n"
     ]
    }
   ],
   "source": [
    "call_X = np.array(call_X)\n",
    "call_Y = np.array(call_Y)\n",
    "\n",
    "put_X = np.array(put_X)\n",
    "put_Y = np.array(put_Y)\n",
    "\n",
    "# 数据处理\n",
    "for i in range(len(call_X)):\n",
    "    if call_Y[i] <= 0:\n",
    "        call_Y[i] = -call_Y[i]\n",
    "        print(i, call_Y[i])\n",
    "    for j in range(10):\n",
    "        for k in range(1, 9):\n",
    "            if call_X[i][j][k] <= 0:\n",
    "                call_X[i][j][k] = -call_X[i][j][k]\n",
    "                print(i,j,k,call_X[i][j][k])\n",
    "\n",
    "for i in range(len(put_X)):\n",
    "    if put_Y[i] <= 0:\n",
    "        put_Y[i] = -put_Y[i]\n",
    "        print(i, put_Y[i])\n",
    "    for j in range(10):\n",
    "        for k in range(1, 9):\n",
    "            if put_X[i][j][k] <= 0:\n",
    "                put_X[i][j][k] = -put_X[i][j][k]\n",
    "                print(i,j,k,put_X[i][j][k])\n",
    "# 正则化\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "call_train_X, call_val_X, call_train_Y, call_val_Y = train_test_split(call_X,\n",
    "                                                                      call_Y,\n",
    "                                                                      test_size=0.2,\n",
    "                                                                      random_state=19011)\n",
    "\n",
    "put_train_X, put_val_X, put_train_Y, put_val_Y = train_test_split(put_X,\n",
    "                                                                  put_Y,\n",
    "                                                                  test_size=0.2,\n",
    "                                                                  random_state=19011)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_37 (Conv1D)           (None, 9, 32)             608       \n",
      "_________________________________________________________________\n",
      "conv1d_38 (Conv1D)           (None, 8, 64)             4160      \n",
      "_________________________________________________________________\n",
      "conv1d_39 (Conv1D)           (None, 7, 128)            16512     \n",
      "_________________________________________________________________\n",
      "conv1d_40 (Conv1D)           (None, 6, 256)            65792     \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 1)                 1537      \n",
      "=================================================================\n",
      "Total params: 88,609\n",
      "Trainable params: 88,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 5000 samples, validate on 50 samples\n",
      "Epoch 1/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 2/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 3/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 4/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 5/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 6/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 7/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 8/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 9/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 10/50\n",
      " - 1s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 11/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 12/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 13/50\n",
      " - 3s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 14/50\n",
      " - 2s - loss: nan - mean_absolute_error: nan - val_loss: nan - val_mean_absolute_error: nan\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-18-a8863b8c2651>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     34\u001B[0m                     \u001B[0mvalidation_data\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mcall_val_X\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m150\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcall_val_Y\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m100\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;36m150\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     35\u001B[0m                     \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m2\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 36\u001B[1;33m                     shuffle=False)\n\u001B[0m\u001B[0;32m     37\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\models.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001B[0m\n\u001B[0;32m    961\u001B[0m                               \u001B[0minitial_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minitial_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    962\u001B[0m                               \u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 963\u001B[1;33m                               validation_steps=validation_steps)\n\u001B[0m\u001B[0;32m    964\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    965\u001B[0m     def evaluate(self, x=None, y=None,\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001B[0m\n\u001B[0;32m   1703\u001B[0m                               \u001B[0minitial_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0minitial_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1704\u001B[0m                               \u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0msteps_per_epoch\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1705\u001B[1;33m                               validation_steps=validation_steps)\n\u001B[0m\u001B[0;32m   1706\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1707\u001B[0m     def evaluate(self, x=None, y=None,\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\engine\\training.py\u001B[0m in \u001B[0;36m_fit_loop\u001B[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001B[0m\n\u001B[0;32m   1233\u001B[0m                         \u001B[0mins_batch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mins_batch\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mi\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtoarray\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1234\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1235\u001B[1;33m                     \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mf\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mins_batch\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1236\u001B[0m                     \u001B[1;32mif\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[0misinstance\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mouts\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlist\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1237\u001B[0m                         \u001B[0mouts\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[0mouts\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, inputs)\u001B[0m\n\u001B[0;32m   2476\u001B[0m         \u001B[0msession\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mget_session\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2477\u001B[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001B[1;32m-> 2478\u001B[1;33m                               **self.session_kwargs)\n\u001B[0m\u001B[0;32m   2479\u001B[0m         \u001B[1;32mreturn\u001B[0m \u001B[0mupdated\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;33m:\u001B[0m\u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0moutputs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2480\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36mrun\u001B[1;34m(self, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m    898\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    899\u001B[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001B[1;32m--> 900\u001B[1;33m                          run_metadata_ptr)\n\u001B[0m\u001B[0;32m    901\u001B[0m       \u001B[1;32mif\u001B[0m \u001B[0mrun_metadata\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    902\u001B[0m         \u001B[0mproto_data\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mtf_session\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTF_GetBuffer\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mrun_metadata_ptr\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_run\u001B[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1133\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mfinal_fetches\u001B[0m \u001B[1;32mor\u001B[0m \u001B[0mfinal_targets\u001B[0m \u001B[1;32mor\u001B[0m \u001B[1;33m(\u001B[0m\u001B[0mhandle\u001B[0m \u001B[1;32mand\u001B[0m \u001B[0mfeed_dict_tensor\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1134\u001B[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001B[1;32m-> 1135\u001B[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001B[0m\u001B[0;32m   1136\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1137\u001B[0m       \u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m[\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_do_run\u001B[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001B[0m\n\u001B[0;32m   1314\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mhandle\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1315\u001B[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001B[1;32m-> 1316\u001B[1;33m                            run_metadata)\n\u001B[0m\u001B[0;32m   1317\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1318\u001B[0m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_do_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0m_prun_fn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeeds\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfetches\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_do_call\u001B[1;34m(self, fn, *args)\u001B[0m\n\u001B[0;32m   1320\u001B[0m   \u001B[1;32mdef\u001B[0m \u001B[0m_do_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1321\u001B[0m     \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1322\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1323\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mOpError\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1324\u001B[0m       \u001B[0mmessage\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcompat\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mas_text\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0me\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mmessage\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_run_fn\u001B[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001B[0m\n\u001B[0;32m   1305\u001B[0m       \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_extend_graph\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1306\u001B[0m       return self._call_tf_sessionrun(\n\u001B[1;32m-> 1307\u001B[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001B[0m\u001B[0;32m   1308\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1309\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_prun_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mhandle\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeed_dict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfetch_list\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mC:\\fun\\annaconda\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001B[0m in \u001B[0;36m_call_tf_sessionrun\u001B[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001B[0m\n\u001B[0;32m   1407\u001B[0m       return tf_session.TF_SessionRun_wrapper(\n\u001B[0;32m   1408\u001B[0m           \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_session\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0moptions\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfeed_dict\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfetch_list\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mtarget_list\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1409\u001B[1;33m           run_metadata)\n\u001B[0m\u001B[0;32m   1410\u001B[0m     \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1411\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0merrors\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mraise_exception_on_not_ok_status\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mstatus\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D , MaxPool2D , Flatten , Dropout\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def Cov_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 2, padding='valid', input_shape=(10, 9), activation=\"selu\"))\n",
    "    model.add(Conv1D(64, 2, padding='valid', activation=\"selu\"))\n",
    "    model.add(Conv1D(128, 2, padding='valid', activation=\"selu\"))\n",
    "    model.add(Conv1D(256, 2, padding='valid', activation=\"selu\"))\n",
    "    #model.add(Dropout(0.25))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    opt = Adam(lr=0.001, clipnorm=1)\n",
    "    model.compile(optimizer=opt, loss=tf.keras.losses.mean_squared_error,\n",
    "                  metrics=['mae'])\n",
    "    model.summary()\n",
    "    return model\n",
    "\n",
    "# fit network\n",
    "cov_model = Cov_model()\n",
    "\n",
    "history = cov_model.fit(call_train_X[10000:15000], call_train_Y[10000:15000],\n",
    "                    epochs=50, batch_size=256,\n",
    "                    validation_data=(call_val_X[100:150], call_val_Y[100:150]),\n",
    "                    verbose=2,\n",
    "                    shuffle=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [
    {
     "data": {
      "text/plain": "54092"
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(call_train_X[0][0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23979284713442395\n",
      "0.7948946814005601\n",
      "0.23951762677246313\n",
      "0.33556320920681204\n",
      "0.7399376326462626\n",
      "0.4396008900280739\n",
      "0.7568089234434277\n",
      "0.5467006080728001\n",
      "0.3175777476532784\n",
      "0.610165572315591\n",
      "0.740746014634295\n",
      "0.7496317674856362\n",
      "0.2733896864533043\n",
      "0.612183686441494\n",
      "0.3406278039214239\n",
      "0.9554814295828681\n",
      "0.21981172811013483\n",
      "0.2687413368525975\n",
      "0.10132240966981021\n",
      "0.5553748036346873\n",
      "0.9422195801466822\n",
      "0.5763673166355193\n",
      "9.960458518798454e-05\n",
      "0.4083206639507294\n",
      "0.7968581829532527\n",
      "0.1328396243033363\n",
      "0.9057814821572647\n",
      "0.23723644117561216\n",
      "0.2692576710178749\n",
      "0.9694110348644029\n",
      "0.6586902810103331\n",
      "0.8379606015177065\n",
      "0.8098933336290486\n",
      "0.4691015281629164\n",
      "0.7328261162207346\n",
      "0.2286847693189581\n",
      "0.6172295050041521\n",
      "0.09502760000626354\n",
      "0.22871299663926137\n",
      "0.021424985249783535\n",
      "0.7204030869565352\n",
      "0.6690719189961862\n",
      "0.31298290138774765\n",
      "0.2131375945724917\n",
      "0.2316547943797883\n",
      "0.47351525617420365\n",
      "0.3698468912959266\n",
      "0.8847275746555036\n",
      "0.7945634746173753\n",
      "0.8899859139310079\n",
      "0.25465550014424343\n",
      "0.20557998760607998\n",
      "0.2541635571932198\n",
      "0.3793108202851625\n",
      "0.5730162326020811\n",
      "0.07520121664983204\n",
      "0.3145371497567848\n",
      "0.5127884932392935\n",
      "0.4348090746300456\n",
      "0.10099669621206131\n",
      "0.7653333435873647\n",
      "0.9068599535682129\n",
      "0.25906384048803843\n",
      "0.64036833841459\n",
      "0.23740302657273982\n",
      "0.5096277008921232\n",
      "0.661944654183734\n",
      "0.7368286499079695\n",
      "0.4273191080637537\n",
      "0.9247180849888516\n",
      "0.5573329934130324\n",
      "0.37781343701204195\n",
      "0.8617621800293338\n",
      "0.14811708140686908\n",
      "0.07594431437604188\n",
      "0.020470578154474617\n",
      "0.2699277676910915\n",
      "0.5815803638072276\n",
      "0.23422228918115573\n",
      "0.08971459026004547\n",
      "0.011019386466632364\n",
      "0.7709160618776105\n",
      "0.5955611073871956\n",
      "0.7193430147197929\n",
      "0.4598383533028343\n",
      "0.6343895475613113\n",
      "0.7729726683233407\n",
      "0.11037691168802477\n",
      "0.015343017890327992\n",
      "0.3055568956324287\n",
      "0.8116788608776752\n",
      "0.6359317782757195\n",
      "0.4650925770119865\n",
      "0.2991322116916637\n",
      "0.5441999912169901\n",
      "0.13113127547273395\n",
      "0.9355107721089813\n",
      "0.49321603508040535\n",
      "0.5258293609961758\n",
      "0.3159563825419178\n",
      "0.12945845902047037\n",
      "0.6389420565132966\n",
      "0.4212291882845468\n",
      "0.9545697812425931\n",
      "0.9282069113593652\n",
      "0.5384111471758368\n",
      "0.2113313832807322\n",
      "0.5243252830199684\n",
      "0.22691482861638512\n",
      "0.024509711825876135\n",
      "0.5225844473109708\n",
      "0.8987977250581471\n",
      "0.3888204639774038\n"
     ]
    }
   ],
   "source": [
    "for i in range(113):\n",
    "    print(random.random())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''画图'''\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import Line\n",
    "\n",
    "output_folder = r'.\\data\\out'\n",
    "csv_list = os.listdir(output_folder)\n",
    "\n",
    "for datafile in csv_list:\n",
    "    csv_path = output_folder +\"\\\\\"+ datafile\n",
    "    data = pd.read_csv(csv_path, encoding = 'utf-8', index_col= False)\n",
    "    data = data['iv']\n",
    "    x = list(range(1,len(data)+1))\n",
    "    #print('x',x)\n",
    "    #print('data', data)\n",
    "    plt.plot(x, data, 'ro-', color='#4169E1', alpha=0.8, linewidth=1, label='iv折线图')\n",
    "    plt.savefig('./data/out_pic/'+ datafile + '.jpg')\n",
    "    plt.clf()\n",
    "    line = (\n",
    "        Line()\n",
    "        .set_global_opts(\n",
    "            tooltip_opts=opts.TooltipOpts(is_show=False),\n",
    "            xaxis_opts=opts.AxisOpts(type_=\"value\"),\n",
    "            yaxis_opts=opts.AxisOpts(\n",
    "                type_=\"value\",\n",
    "                axistick_opts=opts.AxisTickOpts(is_show=True),\n",
    "                splitline_opts=opts.SplitLineOpts(is_show=True),\n",
    "            ),\n",
    "        )\n",
    "        .add_xaxis(xaxis_data=x)\n",
    "        .add_yaxis(\n",
    "            series_name=\"基本折线图\",\n",
    "            y_axis=data,\n",
    "            symbol=\"emptyCircle\",\n",
    "            is_symbol_show=True,\n",
    "            label_opts=opts.LabelOpts(is_show=False),\n",
    "        )\n",
    "    )\n",
    "    line.render('./data/out_pic/'+ datafile + '.html')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Dropout, Conv1D, Flatten\n",
    "\n",
    "\n",
    "# design network\n",
    "def model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, 2, padding='valid', input_shape=(10,10), activation=\"relu\"))\n",
    "    model.add(Conv1D(62, 2, padding='valid', activation=\"relu\"))\n",
    "    model.add(Conv1D(128, 2, padding='valid', activation=\"relu\"))\n",
    "    model.add(Conv1D(256, 2, padding='valid', activation=\"relu\"))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    # plot history\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    return model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def model1():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(10, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(loss='mae', optimizer='adam')\n",
    "    # fit network\n",
    "    history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "    # plot history\n",
    "    pyplot.plot(history.history['loss'], label='train')\n",
    "    pyplot.plot(history.history['val_loss'], label='test')\n",
    "    pyplot.legend()\n",
    "    pyplot.show()\n",
    "\n",
    "    return model1\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "49cb93f377a7abe7414b7b0f21fb3017538004a126cf690fb524202736b7fb92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}